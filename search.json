[
  {
    "objectID": "posts/master-the-art-of-function-calling-in-openai-assistants-api-a-comprehensive-guide-for-beginners/assistants_function_calling.html",
    "href": "posts/master-the-art-of-function-calling-in-openai-assistants-api-a-comprehensive-guide-for-beginners/assistants_function_calling.html",
    "title": "Master the Art of Function Calling in OpenAI Assistants API: A Comprehensive Guide for Beginners",
    "section": "",
    "text": "# !pip3 install openai -U\n\nWelcome to our comprehensive guide on leveraging function calling in the OpenAI Assistant API. Whether you’re a seasoned developer or a curious beginner, this tutorial is designed to help you understand and implement this powerful feature in your AI projects.\nHere’s what we’ll be diving into:\n\nThe basics of function calling in the OpenAI Assistant API\nSteps to create an assistant\nCrafting a message and initiating a thread\nIdentifying when a message requires a function call\nDetermining which function to call and what arguments to pass\nRetrieving the response from a function call\nUnderstanding the final response\n\nOpenAI Assistants are equipped with a variety of tools, including retrieval, code interpretation, and function calling. In this guide, we’ll be focusing primarily on the function calling capabilities.\nTo illustrate these concepts, we’ll walk you through a simple demo. We’ll start by demonstrating a common challenge - reversing a string - and then show you how to overcome this challenge by creating a function that reverses the string and integrating it with the assistant.\nOur goal is to provide you with a clear, practical understanding of function calling in the OpenAI Assistant API, empowering you to create more dynamic and interactive AI applications. Let’s get started!\nIn general, assistants can use tools such as retrrieval, code interpreter, and function calling.\nIn this tutorial we focus more on function calling capabilities of assistants.\nWe create a simple demo that shows the failure of reversing a string and then we create a function that reverses the string and connect it with the assistant.\n\n# dictionary print indentatio\n\n\nimport json\nimport os\nfrom dotenv import load_dotenv\nimport openai\nfrom openai import OpenAI\nclient = OpenAI()\nload_dotenv()\n# openai key\nOPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\nopenai.api_key = OPENAI_API_KEY\nfrom IPython.display import display, Markdown\n\n\n# openai version\nopenai.__version__\n\n'1.6.1'\n\n\n\nresponse = client.chat.completions.create(\n    model=\"gpt-4-1106-preview\",\n    messages=[\n        {\"role\": \"user\", \"content\": \"reverse the string openaichatgpt\"},\n    ],\n    temperature=0.3,\n    seed=1,\n)\n\n\ndisplay(Markdown(response.choices[0].message.content))\n\nTo reverse the string “openaichatgpt”, you would simply reverse the order of the characters to get “tpgtahciapeneo”.\n\n\n\n\"tpgtahciapeneo\" == \"openaichatgpt\"[::-1]\n\nFalse\n\n\nLarge Language Models use tokens to split text into smaller pieces, and reversing a string is not a usual data that is has seen during training, so it is not able to predict it correctly.\nWe can fix this by creating a function that will reverse the string, and use the model to ask us to call the function and get results and pass it to the model.\n\ndef reverse_string(string):\n    return string[::-1]\n\n\nCreating an Assistant\n\n# function_json for reverse_string\nfunction_json = {'type':'function',\n            'function':{\n                'name': 'reverse_string',\n                'parameters':{\n                    \"type\":\"object\",\n                      \"properties\":{\n                          \"string\": {'type':'string','description':\"A single word\"},\n                      },\n                    'required' : [\"string\"]\n                }\n\n    }\n}\n\n\navailable_functions = {\n    \"reverse_string\": reverse_string\n}\n\n\nfrom openai import OpenAI\nclient = OpenAI()\n\n\nassistant = client.beta.assistants.create(\n    name=\"Python Tutor\",\n    instructions=\"You are a personal python tutor.\",\n    tools=[function_json],\n    model=\"gpt-4-1106-preview\"\n)\n\n\nassistant\n\nAssistant(id='asst_UQEBrB5fuKnzx472Sf5qWYdH', created_at=1704457106, description=None, file_ids=[], instructions='You are a personal python tutor.', metadata={}, model='gpt-4-1106-preview', name='Python Tutor', object='assistant', tools=[ToolFunction(function=FunctionDefinition(name='reverse_string', description=None, parameters={'type': 'object', 'properties': {'string': {'type': 'string', 'description': 'A single word'}}, 'required': ['string']}), type='function')])\n\n\n\nprint(json.dumps(assistant.model_dump(), indent=4))\n\n{\n    \"id\": \"asst_UQEBrB5fuKnzx472Sf5qWYdH\",\n    \"created_at\": 1704457106,\n    \"description\": null,\n    \"file_ids\": [],\n    \"instructions\": \"You are a personal python tutor.\",\n    \"metadata\": {},\n    \"model\": \"gpt-4-1106-preview\",\n    \"name\": \"Python Tutor\",\n    \"object\": \"assistant\",\n    \"tools\": [\n        {\n            \"function\": {\n                \"name\": \"reverse_string\",\n                \"description\": null,\n                \"parameters\": {\n                    \"type\": \"object\",\n                    \"properties\": {\n                        \"string\": {\n                            \"type\": \"string\",\n                            \"description\": \"A single word\"\n                        }\n                    },\n                    \"required\": [\n                        \"string\"\n                    ]\n                }\n            },\n            \"type\": \"function\"\n        }\n    ]\n}\n\n\n\ntype(assistant)\n\nopenai.types.beta.assistant.Assistant\n\n\n\n\nThread\n\nthread = client.beta.threads.create()\n\n\nthread.model_dump()\n\n{'id': 'thread_3fT59LTUrodHJPjBQYsIYm6F',\n 'created_at': 1704457106,\n 'metadata': {},\n 'object': 'thread'}\n\n\n\nthread\n\nThread(id='thread_3fT59LTUrodHJPjBQYsIYm6F', created_at=1704457106, metadata={}, object='thread')\n\n\n\n\nAdd a Message to a Thread\n\nmessage = client.beta.threads.messages.create(\n    thread_id=thread.id,\n    role=\"user\",\n    content=\"what are different loops in python?\"\n)\n\n\nmessage\n\nThreadMessage(id='msg_UDx8nMLlKxvriXAEBeW0AJ9f', assistant_id=None, content=[MessageContentText(text=Text(annotations=[], value='what are different loops in python?'), type='text')], created_at=1704457107, file_ids=[], metadata={}, object='thread.message', role='user', run_id=None, thread_id='thread_3fT59LTUrodHJPjBQYsIYm6F')\n\n\n\nmessage.model_dump()\n\n{'id': 'msg_UDx8nMLlKxvriXAEBeW0AJ9f',\n 'assistant_id': None,\n 'content': [{'text': {'annotations': [],\n    'value': 'what are different loops in python?'},\n   'type': 'text'}],\n 'created_at': 1704457107,\n 'file_ids': [],\n 'metadata': {},\n 'object': 'thread.message',\n 'role': 'user',\n 'run_id': None,\n 'thread_id': 'thread_3fT59LTUrodHJPjBQYsIYm6F'}\n\n\n\nthread_messages = client.beta.threads.messages.list(thread_id=thread.id)\nthread_messages.data\n\n[ThreadMessage(id='msg_UDx8nMLlKxvriXAEBeW0AJ9f', assistant_id=None, content=[MessageContentText(text=Text(annotations=[], value='what are different loops in python?'), type='text')], created_at=1704457107, file_ids=[], metadata={}, object='thread.message', role='user', run_id=None, thread_id='thread_3fT59LTUrodHJPjBQYsIYm6F')]\n\n\n\nthread_messages.model_dump()\n\n{'data': [{'id': 'msg_UDx8nMLlKxvriXAEBeW0AJ9f',\n   'assistant_id': None,\n   'content': [{'text': {'annotations': [],\n      'value': 'what are different loops in python?'},\n     'type': 'text'}],\n   'created_at': 1704457107,\n   'file_ids': [],\n   'metadata': {},\n   'object': 'thread.message',\n   'role': 'user',\n   'run_id': None,\n   'thread_id': 'thread_3fT59LTUrodHJPjBQYsIYm6F'}],\n 'object': 'list',\n 'first_id': 'msg_UDx8nMLlKxvriXAEBeW0AJ9f',\n 'last_id': 'msg_UDx8nMLlKxvriXAEBeW0AJ9f',\n 'has_more': False}\n\n\n\nrun = client.beta.threads.runs.create(\n  thread_id=thread.id,\n  assistant_id=assistant.id,\n)\n\n\nprint(json.dumps(run.model_dump(), indent=4))\n\n{\n    \"id\": \"run_BLZnD60Vl7wePLUsdmUFR5zd\",\n    \"assistant_id\": \"asst_UQEBrB5fuKnzx472Sf5qWYdH\",\n    \"cancelled_at\": null,\n    \"completed_at\": null,\n    \"created_at\": 1704457108,\n    \"expires_at\": 1704457708,\n    \"failed_at\": null,\n    \"file_ids\": [],\n    \"instructions\": \"You are a personal python tutor.\",\n    \"last_error\": null,\n    \"metadata\": {},\n    \"model\": \"gpt-4-1106-preview\",\n    \"object\": \"thread.run\",\n    \"required_action\": null,\n    \"started_at\": null,\n    \"status\": \"queued\",\n    \"thread_id\": \"thread_3fT59LTUrodHJPjBQYsIYm6F\",\n    \"tools\": [\n        {\n            \"function\": {\n                \"name\": \"reverse_string\",\n                \"description\": null,\n                \"parameters\": {\n                    \"type\": \"object\",\n                    \"properties\": {\n                        \"string\": {\n                            \"type\": \"string\",\n                            \"description\": \"A single word\"\n                        }\n                    },\n                    \"required\": [\n                        \"string\"\n                    ]\n                }\n            },\n            \"type\": \"function\"\n        }\n    ]\n}\n\n\n\nrun = client.beta.threads.runs.retrieve(\n  thread_id=thread.id,\n  run_id=run.id\n)\n\n\nprint(json.dumps(run.model_dump(), indent=4))\n\n{\n    \"id\": \"run_BLZnD60Vl7wePLUsdmUFR5zd\",\n    \"assistant_id\": \"asst_UQEBrB5fuKnzx472Sf5qWYdH\",\n    \"cancelled_at\": null,\n    \"completed_at\": null,\n    \"created_at\": 1704457108,\n    \"expires_at\": 1704457708,\n    \"failed_at\": null,\n    \"file_ids\": [],\n    \"instructions\": \"You are a personal python tutor.\",\n    \"last_error\": null,\n    \"metadata\": {},\n    \"model\": \"gpt-4-1106-preview\",\n    \"object\": \"thread.run\",\n    \"required_action\": null,\n    \"started_at\": 1704457108,\n    \"status\": \"in_progress\",\n    \"thread_id\": \"thread_3fT59LTUrodHJPjBQYsIYm6F\",\n    \"tools\": [\n        {\n            \"function\": {\n                \"name\": \"reverse_string\",\n                \"description\": null,\n                \"parameters\": {\n                    \"type\": \"object\",\n                    \"properties\": {\n                        \"string\": {\n                            \"type\": \"string\",\n                            \"description\": \"A single word\"\n                        }\n                    },\n                    \"required\": [\n                        \"string\"\n                    ]\n                }\n            },\n            \"type\": \"function\"\n        }\n    ]\n}\n\n\n\nrun\n\nRun(id='run_BLZnD60Vl7wePLUsdmUFR5zd', assistant_id='asst_UQEBrB5fuKnzx472Sf5qWYdH', cancelled_at=None, completed_at=None, created_at=1704457108, expires_at=1704457708, failed_at=None, file_ids=[], instructions='You are a personal python tutor.', last_error=None, metadata={}, model='gpt-4-1106-preview', object='thread.run', required_action=None, started_at=1704457108, status='in_progress', thread_id='thread_3fT59LTUrodHJPjBQYsIYm6F', tools=[ToolAssistantToolsFunction(function=FunctionDefinition(name='reverse_string', description=None, parameters={'type': 'object', 'properties': {'string': {'type': 'string', 'description': 'A single word'}}, 'required': ['string']}), type='function')])\n\n\n\nrun.status\n\n'in_progress'\n\n\n\nimport time\n\n\nwhile run.status == \"queued\" or run.status == \"in_progress\":\n    run = client.beta.threads.runs.retrieve(\n      thread_id=thread.id,\n      run_id=run.id\n    )\n    print(run.status)\n    time.sleep(2)\n    \n\nin_progress\nin_progress\nin_progress\nin_progress\nin_progress\nin_progress\nin_progress\nin_progress\nin_progress\nin_progress\nin_progress\nin_progress\nin_progress\ncompleted\n\n\n\nrun\n\nRun(id='run_BLZnD60Vl7wePLUsdmUFR5zd', assistant_id='asst_UQEBrB5fuKnzx472Sf5qWYdH', cancelled_at=None, completed_at=1704457140, created_at=1704457108, expires_at=None, failed_at=None, file_ids=[], instructions='You are a personal python tutor.', last_error=None, metadata={}, model='gpt-4-1106-preview', object='thread.run', required_action=None, started_at=1704457108, status='completed', thread_id='thread_3fT59LTUrodHJPjBQYsIYm6F', tools=[ToolAssistantToolsFunction(function=FunctionDefinition(name='reverse_string', description=None, parameters={'type': 'object', 'properties': {'string': {'type': 'string', 'description': 'A single word'}}, 'required': ['string']}), type='function')])\n\n\n\nmessages = client.beta.threads.messages.list(\n  thread_id=thread.id\n)\n\nmessages\n\nSyncCursorPage[ThreadMessage](data=[ThreadMessage(id='msg_a5FW3oicgn271ztQwcIa6kQ6', assistant_id='asst_UQEBrB5fuKnzx472Sf5qWYdH', content=[MessageContentText(text=Text(annotations=[], value='In Python, there are two primary types of loops that allow you to execute a block of code repeatedly:\\n\\n1. `for` Loop: This loop is used for iterating over a sequence (which could be a list, tuple, dictionary, set, or string) with the ability to execute a block of code for each item in the sequence. An example of a `for` loop:\\n\\n```python\\nfor item in [\"apple\", \"banana\", \"cherry\"]:\\n    print(item)\\n```\\n\\n2. `while` Loop: This loop repeatedly executes the target statement(s) as long as the given condition is true. The condition is evaluated before executing the body of the loop. Here\\'s an example of a `while` loop:\\n\\n```python\\ncount = 0\\nwhile count &lt; 5:\\n    print(count)\\n    count += 1\\n```\\n\\nPython also provides some loop control statements that can be used within these loops:\\n\\n- `break`: Terminates the loop and transfers execution to the statement immediately following the loop.\\n- `continue`: Skips the remaining part of the loop for the current iteration and moves to the next iteration.\\n- `else`: An optional clause associated with loops that is executed if the loop completes normally (i.e., not terminated by a `break` statement).\\n\\nHere\\'s an example of using `break`, `continue`, and `else` with a `for` loop:\\n\\n```python\\nfor num in range(2, 10):\\n    if num % 2 == 0:\\n        print(\"Found an even number\", num)\\n        continue\\n    print(\"Found a number\", num)\\nelse:\\n    print(\"The loop is completed without a break statement.\")\\n```\\n\\nAnd an example using `while` loop:\\n\\n```python\\ncount = 1\\nwhile count &lt; 10:\\n    if count == 5:\\n        break\\n    print(count)\\n    count += 1\\nelse:\\n    print(\"Reached the value of 5 and stopped the loop with a break statement.\")\\n```\\n\\nAdditionally, Python allows the use of nested loops (a loop inside another loop), which can be useful for more complex iteration scenarios. However, it\\'s important to use them judiciously as they can lead to high computational complexity, especially with large datasets.'), type='text')], created_at=1704457109, file_ids=[], metadata={}, object='thread.message', role='assistant', run_id='run_BLZnD60Vl7wePLUsdmUFR5zd', thread_id='thread_3fT59LTUrodHJPjBQYsIYm6F'), ThreadMessage(id='msg_UDx8nMLlKxvriXAEBeW0AJ9f', assistant_id=None, content=[MessageContentText(text=Text(annotations=[], value='what are different loops in python?'), type='text')], created_at=1704457107, file_ids=[], metadata={}, object='thread.message', role='user', run_id=None, thread_id='thread_3fT59LTUrodHJPjBQYsIYm6F')], object='list', first_id='msg_a5FW3oicgn271ztQwcIa6kQ6', last_id='msg_UDx8nMLlKxvriXAEBeW0AJ9f', has_more=False)\n\n\n\nprint(json.dumps(messages.model_dump(), indent=4))\n\n{\n    \"data\": [\n        {\n            \"id\": \"msg_a5FW3oicgn271ztQwcIa6kQ6\",\n            \"assistant_id\": \"asst_UQEBrB5fuKnzx472Sf5qWYdH\",\n            \"content\": [\n                {\n                    \"text\": {\n                        \"annotations\": [],\n                        \"value\": \"In Python, there are two primary types of loops that allow you to execute a block of code repeatedly:\\n\\n1. `for` Loop: This loop is used for iterating over a sequence (which could be a list, tuple, dictionary, set, or string) with the ability to execute a block of code for each item in the sequence. An example of a `for` loop:\\n\\n```python\\nfor item in [\\\"apple\\\", \\\"banana\\\", \\\"cherry\\\"]:\\n    print(item)\\n```\\n\\n2. `while` Loop: This loop repeatedly executes the target statement(s) as long as the given condition is true. The condition is evaluated before executing the body of the loop. Here's an example of a `while` loop:\\n\\n```python\\ncount = 0\\nwhile count &lt; 5:\\n    print(count)\\n    count += 1\\n```\\n\\nPython also provides some loop control statements that can be used within these loops:\\n\\n- `break`: Terminates the loop and transfers execution to the statement immediately following the loop.\\n- `continue`: Skips the remaining part of the loop for the current iteration and moves to the next iteration.\\n- `else`: An optional clause associated with loops that is executed if the loop completes normally (i.e., not terminated by a `break` statement).\\n\\nHere's an example of using `break`, `continue`, and `else` with a `for` loop:\\n\\n```python\\nfor num in range(2, 10):\\n    if num % 2 == 0:\\n        print(\\\"Found an even number\\\", num)\\n        continue\\n    print(\\\"Found a number\\\", num)\\nelse:\\n    print(\\\"The loop is completed without a break statement.\\\")\\n```\\n\\nAnd an example using `while` loop:\\n\\n```python\\ncount = 1\\nwhile count &lt; 10:\\n    if count == 5:\\n        break\\n    print(count)\\n    count += 1\\nelse:\\n    print(\\\"Reached the value of 5 and stopped the loop with a break statement.\\\")\\n```\\n\\nAdditionally, Python allows the use of nested loops (a loop inside another loop), which can be useful for more complex iteration scenarios. However, it's important to use them judiciously as they can lead to high computational complexity, especially with large datasets.\"\n                    },\n                    \"type\": \"text\"\n                }\n            ],\n            \"created_at\": 1704457109,\n            \"file_ids\": [],\n            \"metadata\": {},\n            \"object\": \"thread.message\",\n            \"role\": \"assistant\",\n            \"run_id\": \"run_BLZnD60Vl7wePLUsdmUFR5zd\",\n            \"thread_id\": \"thread_3fT59LTUrodHJPjBQYsIYm6F\"\n        },\n        {\n            \"id\": \"msg_UDx8nMLlKxvriXAEBeW0AJ9f\",\n            \"assistant_id\": null,\n            \"content\": [\n                {\n                    \"text\": {\n                        \"annotations\": [],\n                        \"value\": \"what are different loops in python?\"\n                    },\n                    \"type\": \"text\"\n                }\n            ],\n            \"created_at\": 1704457107,\n            \"file_ids\": [],\n            \"metadata\": {},\n            \"object\": \"thread.message\",\n            \"role\": \"user\",\n            \"run_id\": null,\n            \"thread_id\": \"thread_3fT59LTUrodHJPjBQYsIYm6F\"\n        }\n    ],\n    \"object\": \"list\",\n    \"first_id\": \"msg_a5FW3oicgn271ztQwcIa6kQ6\",\n    \"last_id\": \"msg_UDx8nMLlKxvriXAEBeW0AJ9f\",\n    \"has_more\": false\n}\n\n\n\ndisplay(Markdown(messages.data[0].content[0].text.value))\n\nIn Python, there are two primary types of loops that allow you to execute a block of code repeatedly:\n\nfor Loop: This loop is used for iterating over a sequence (which could be a list, tuple, dictionary, set, or string) with the ability to execute a block of code for each item in the sequence. An example of a for loop:\n\nfor item in [\"apple\", \"banana\", \"cherry\"]:\n    print(item)\n\nwhile Loop: This loop repeatedly executes the target statement(s) as long as the given condition is true. The condition is evaluated before executing the body of the loop. Here’s an example of a while loop:\n\ncount = 0\nwhile count &lt; 5:\n    print(count)\n    count += 1\nPython also provides some loop control statements that can be used within these loops:\n\nbreak: Terminates the loop and transfers execution to the statement immediately following the loop.\ncontinue: Skips the remaining part of the loop for the current iteration and moves to the next iteration.\nelse: An optional clause associated with loops that is executed if the loop completes normally (i.e., not terminated by a break statement).\n\nHere’s an example of using break, continue, and else with a for loop:\nfor num in range(2, 10):\n    if num % 2 == 0:\n        print(\"Found an even number\", num)\n        continue\n    print(\"Found a number\", num)\nelse:\n    print(\"The loop is completed without a break statement.\")\nAnd an example using while loop:\ncount = 1\nwhile count &lt; 10:\n    if count == 5:\n        break\n    print(count)\n    count += 1\nelse:\n    print(\"Reached the value of 5 and stopped the loop with a break statement.\")\nAdditionally, Python allows the use of nested loops (a loop inside another loop), which can be useful for more complex iteration scenarios. However, it’s important to use them judiciously as they can lead to high computational complexity, especially with large datasets.\n\n\n\n# new message\nmessage = client.beta.threads.messages.create(\n    thread_id=thread.id,\n    role=\"user\",\n    content=\"what's the reverse of the string openaichatgpt?\"\n)\n\n\n# new run\nrun = client.beta.threads.runs.create(\n  thread_id=thread.id,\n  assistant_id=assistant.id,\n)\n\n# wait for run to complete\nwhile run.status == \"queued\" or run.status == \"in_progress\":\n    run = client.beta.threads.runs.retrieve(\n      thread_id=thread.id,\n      run_id=run.id\n    )\n    print(run.status)\n    time.sleep(2)\n\nin_progress\nin_progress\nrequires_action\n\n\n\nrun.status\n\n'requires_action'\n\n\n\nprint(json.dumps(run.model_dump(), indent=4))\n\n{\n    \"id\": \"run_dmH9mQUYjLLQJEYuXZQZJOHH\",\n    \"assistant_id\": \"asst_UQEBrB5fuKnzx472Sf5qWYdH\",\n    \"cancelled_at\": null,\n    \"completed_at\": null,\n    \"created_at\": 1704457145,\n    \"expires_at\": 1704457745,\n    \"failed_at\": null,\n    \"file_ids\": [],\n    \"instructions\": \"You are a personal python tutor.\",\n    \"last_error\": null,\n    \"metadata\": {},\n    \"model\": \"gpt-4-1106-preview\",\n    \"object\": \"thread.run\",\n    \"required_action\": {\n        \"submit_tool_outputs\": {\n            \"tool_calls\": [\n                {\n                    \"id\": \"call_aQzOoDu3V00J5lkG6zVNtdqc\",\n                    \"function\": {\n                        \"arguments\": \"{\\\"string\\\":\\\"openaichatgpt\\\"}\",\n                        \"name\": \"reverse_string\"\n                    },\n                    \"type\": \"function\"\n                }\n            ]\n        },\n        \"type\": \"submit_tool_outputs\"\n    },\n    \"started_at\": 1704457145,\n    \"status\": \"requires_action\",\n    \"thread_id\": \"thread_3fT59LTUrodHJPjBQYsIYm6F\",\n    \"tools\": [\n        {\n            \"function\": {\n                \"name\": \"reverse_string\",\n                \"description\": null,\n                \"parameters\": {\n                    \"type\": \"object\",\n                    \"properties\": {\n                        \"string\": {\n                            \"type\": \"string\",\n                            \"description\": \"A single word\"\n                        }\n                    },\n                    \"required\": [\n                        \"string\"\n                    ]\n                }\n            },\n            \"type\": \"function\"\n        }\n    ]\n}\n\n\n\nrun.required_action\n\nRequiredAction(submit_tool_outputs=RequiredActionSubmitToolOutputs(tool_calls=[RequiredActionFunctionToolCall(id='call_aQzOoDu3V00J5lkG6zVNtdqc', function=Function(arguments='{\"string\":\"openaichatgpt\"}', name='reverse_string'), type='function')]), type='submit_tool_outputs')\n\n\n\nif run.status == \"requires_action\":\n    tool_call = run.required_action.submit_tool_outputs.tool_calls[0]\n    print(\"Tool call: \", tool_call)\n    function_name = tool_call.function.name\n    print(\"Function name: \", function_name)\n    arguments = json.loads(tool_call.function.arguments)\n    print(\"Function arguments: \", arguments)\n\nTool call:  RequiredActionFunctionToolCall(id='call_aQzOoDu3V00J5lkG6zVNtdqc', function=Function(arguments='{\"string\":\"openaichatgpt\"}', name='reverse_string'), type='function')\nFunction name:  reverse_string\nFunction arguments:  {'string': 'openaichatgpt'}\n\n\n\n# call the function\nif run.status == \"requires_action\":\n    tool_call = run.required_action.submit_tool_outputs.tool_calls[0]\n    function_name = tool_call.function.name\n    arguments = json.loads(tool_call.function.arguments)\n    function = available_functions[function_name]\n    output = function(**arguments)\n    print(\"Function output: \", output)\n\nFunction output:  tpgtahcianepo\n\n\n\nprint(json.dumps(run.model_dump(), indent=4))\n\n{\n    \"id\": \"run_dmH9mQUYjLLQJEYuXZQZJOHH\",\n    \"assistant_id\": \"asst_UQEBrB5fuKnzx472Sf5qWYdH\",\n    \"cancelled_at\": null,\n    \"completed_at\": null,\n    \"created_at\": 1704457145,\n    \"expires_at\": 1704457745,\n    \"failed_at\": null,\n    \"file_ids\": [],\n    \"instructions\": \"You are a personal python tutor.\",\n    \"last_error\": null,\n    \"metadata\": {},\n    \"model\": \"gpt-4-1106-preview\",\n    \"object\": \"thread.run\",\n    \"required_action\": {\n        \"submit_tool_outputs\": {\n            \"tool_calls\": [\n                {\n                    \"id\": \"call_aQzOoDu3V00J5lkG6zVNtdqc\",\n                    \"function\": {\n                        \"arguments\": \"{\\\"string\\\":\\\"openaichatgpt\\\"}\",\n                        \"name\": \"reverse_string\"\n                    },\n                    \"type\": \"function\"\n                }\n            ]\n        },\n        \"type\": \"submit_tool_outputs\"\n    },\n    \"started_at\": 1704457145,\n    \"status\": \"requires_action\",\n    \"thread_id\": \"thread_3fT59LTUrodHJPjBQYsIYm6F\",\n    \"tools\": [\n        {\n            \"function\": {\n                \"name\": \"reverse_string\",\n                \"description\": null,\n                \"parameters\": {\n                    \"type\": \"object\",\n                    \"properties\": {\n                        \"string\": {\n                            \"type\": \"string\",\n                            \"description\": \"A single word\"\n                        }\n                    },\n                    \"required\": [\n                        \"string\"\n                    ]\n                }\n            },\n            \"type\": \"function\"\n        }\n    ]\n}\n\n\n\n\nLet the Model Know about the function outputs\n\nrun = client.beta.threads.runs.submit_tool_outputs(\n    thread_id=thread.id,\n    run_id=run.id,\n    tool_outputs=[{\"tool_call_id\": tool_call.id, \"output\": json.dumps(output)}],\n)\n\n\nwhile run.status == \"queued\" or run.status == \"in_progress\":\n    run = client.beta.threads.runs.retrieve(\n      thread_id=thread.id,\n      run_id=run.id\n    )\n    print(run.status)\n    time.sleep(2)\n\nin_progress\ncompleted\n\n\n\n\nRetrieve the message from history and display the output\n\nmessages = client.beta.threads.messages.list(\n    thread_id=thread.id\n    )\n\n\nprint(json.dumps(messages.model_dump(), indent=4))\n\n{\n    \"data\": [\n        {\n            \"id\": \"msg_vp29v6UA7Amr7isw4LdGNhcW\",\n            \"assistant_id\": \"asst_UQEBrB5fuKnzx472Sf5qWYdH\",\n            \"content\": [\n                {\n                    \"text\": {\n                        \"annotations\": [],\n                        \"value\": \"The reverse of the string \\\"openaichatgpt\\\" is \\\"tpgtahcianepo\\\".\"\n                    },\n                    \"type\": \"text\"\n                }\n            ],\n            \"created_at\": 1704457154,\n            \"file_ids\": [],\n            \"metadata\": {},\n            \"object\": \"thread.message\",\n            \"role\": \"assistant\",\n            \"run_id\": \"run_dmH9mQUYjLLQJEYuXZQZJOHH\",\n            \"thread_id\": \"thread_3fT59LTUrodHJPjBQYsIYm6F\"\n        },\n        {\n            \"id\": \"msg_QPbWzZkoRFveMIRPWtvREz0s\",\n            \"assistant_id\": null,\n            \"content\": [\n                {\n                    \"text\": {\n                        \"annotations\": [],\n                        \"value\": \"what's the reverse of the string openaichatgpt?\"\n                    },\n                    \"type\": \"text\"\n                }\n            ],\n            \"created_at\": 1704457145,\n            \"file_ids\": [],\n            \"metadata\": {},\n            \"object\": \"thread.message\",\n            \"role\": \"user\",\n            \"run_id\": null,\n            \"thread_id\": \"thread_3fT59LTUrodHJPjBQYsIYm6F\"\n        },\n        {\n            \"id\": \"msg_a5FW3oicgn271ztQwcIa6kQ6\",\n            \"assistant_id\": \"asst_UQEBrB5fuKnzx472Sf5qWYdH\",\n            \"content\": [\n                {\n                    \"text\": {\n                        \"annotations\": [],\n                        \"value\": \"In Python, there are two primary types of loops that allow you to execute a block of code repeatedly:\\n\\n1. `for` Loop: This loop is used for iterating over a sequence (which could be a list, tuple, dictionary, set, or string) with the ability to execute a block of code for each item in the sequence. An example of a `for` loop:\\n\\n```python\\nfor item in [\\\"apple\\\", \\\"banana\\\", \\\"cherry\\\"]:\\n    print(item)\\n```\\n\\n2. `while` Loop: This loop repeatedly executes the target statement(s) as long as the given condition is true. The condition is evaluated before executing the body of the loop. Here's an example of a `while` loop:\\n\\n```python\\ncount = 0\\nwhile count &lt; 5:\\n    print(count)\\n    count += 1\\n```\\n\\nPython also provides some loop control statements that can be used within these loops:\\n\\n- `break`: Terminates the loop and transfers execution to the statement immediately following the loop.\\n- `continue`: Skips the remaining part of the loop for the current iteration and moves to the next iteration.\\n- `else`: An optional clause associated with loops that is executed if the loop completes normally (i.e., not terminated by a `break` statement).\\n\\nHere's an example of using `break`, `continue`, and `else` with a `for` loop:\\n\\n```python\\nfor num in range(2, 10):\\n    if num % 2 == 0:\\n        print(\\\"Found an even number\\\", num)\\n        continue\\n    print(\\\"Found a number\\\", num)\\nelse:\\n    print(\\\"The loop is completed without a break statement.\\\")\\n```\\n\\nAnd an example using `while` loop:\\n\\n```python\\ncount = 1\\nwhile count &lt; 10:\\n    if count == 5:\\n        break\\n    print(count)\\n    count += 1\\nelse:\\n    print(\\\"Reached the value of 5 and stopped the loop with a break statement.\\\")\\n```\\n\\nAdditionally, Python allows the use of nested loops (a loop inside another loop), which can be useful for more complex iteration scenarios. However, it's important to use them judiciously as they can lead to high computational complexity, especially with large datasets.\"\n                    },\n                    \"type\": \"text\"\n                }\n            ],\n            \"created_at\": 1704457109,\n            \"file_ids\": [],\n            \"metadata\": {},\n            \"object\": \"thread.message\",\n            \"role\": \"assistant\",\n            \"run_id\": \"run_BLZnD60Vl7wePLUsdmUFR5zd\",\n            \"thread_id\": \"thread_3fT59LTUrodHJPjBQYsIYm6F\"\n        },\n        {\n            \"id\": \"msg_UDx8nMLlKxvriXAEBeW0AJ9f\",\n            \"assistant_id\": null,\n            \"content\": [\n                {\n                    \"text\": {\n                        \"annotations\": [],\n                        \"value\": \"what are different loops in python?\"\n                    },\n                    \"type\": \"text\"\n                }\n            ],\n            \"created_at\": 1704457107,\n            \"file_ids\": [],\n            \"metadata\": {},\n            \"object\": \"thread.message\",\n            \"role\": \"user\",\n            \"run_id\": null,\n            \"thread_id\": \"thread_3fT59LTUrodHJPjBQYsIYm6F\"\n        }\n    ],\n    \"object\": \"list\",\n    \"first_id\": \"msg_vp29v6UA7Amr7isw4LdGNhcW\",\n    \"last_id\": \"msg_UDx8nMLlKxvriXAEBeW0AJ9f\",\n    \"has_more\": false\n}\n\n\n\nfor message in messages.data:\n    display(Markdown(message.content[0].text.value))\n    print(\"*\" * 80)\n\nThe reverse of the string “openaichatgpt” is “tpgtahcianepo”.\n\n\n********************************************************************************\n********************************************************************************\n********************************************************************************\n********************************************************************************\n\n\nwhat’s the reverse of the string openaichatgpt?\n\n\nIn Python, there are two primary types of loops that allow you to execute a block of code repeatedly:\n\nfor Loop: This loop is used for iterating over a sequence (which could be a list, tuple, dictionary, set, or string) with the ability to execute a block of code for each item in the sequence. An example of a for loop:\n\nfor item in [\"apple\", \"banana\", \"cherry\"]:\n    print(item)\n\nwhile Loop: This loop repeatedly executes the target statement(s) as long as the given condition is true. The condition is evaluated before executing the body of the loop. Here’s an example of a while loop:\n\ncount = 0\nwhile count &lt; 5:\n    print(count)\n    count += 1\nPython also provides some loop control statements that can be used within these loops:\n\nbreak: Terminates the loop and transfers execution to the statement immediately following the loop.\ncontinue: Skips the remaining part of the loop for the current iteration and moves to the next iteration.\nelse: An optional clause associated with loops that is executed if the loop completes normally (i.e., not terminated by a break statement).\n\nHere’s an example of using break, continue, and else with a for loop:\nfor num in range(2, 10):\n    if num % 2 == 0:\n        print(\"Found an even number\", num)\n        continue\n    print(\"Found a number\", num)\nelse:\n    print(\"The loop is completed without a break statement.\")\nAnd an example using while loop:\ncount = 1\nwhile count &lt; 10:\n    if count == 5:\n        break\n    print(count)\n    count += 1\nelse:\n    print(\"Reached the value of 5 and stopped the loop with a break statement.\")\nAdditionally, Python allows the use of nested loops (a loop inside another loop), which can be useful for more complex iteration scenarios. However, it’s important to use them judiciously as they can lead to high computational complexity, especially with large datasets.\n\n\nwhat are different loops in python?\n\n\n\n\nDelete the Assistant\n\nresponse = client.beta.assistants.delete(assistant_id=assistant.id)\nprint(response)\n\nAssistantDeleted(id='asst_UQEBrB5fuKnzx472Sf5qWYdH', deleted=True, object='assistant.deleted')\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items\n\n Back to top"
  },
  {
    "objectID": "posts/openai-parallel-function-calling-handson-tools/function_calling.html",
    "href": "posts/openai-parallel-function-calling-handson-tools/function_calling.html",
    "title": "MoodCast: Leveraging OpenAI Parallel Function Calling for Real-Time Weather-Based Music Playlists",
    "section": "",
    "text": "This blog post introduces “MoodCast,” a project that leverages OpenAI’s function calling feature to create real-time, weather-based music playlists. By integrating the OpenWeather and Spotify APIs, MoodCast demonstrates the power and flexibility of OpenAI’s function calling in a practical, engaging application.\nOpenAI’s function calling feature allows developers to describe a function, and the model generates a JSON output containing arguments. This feature doesn’t call any function itself, but it generates the JSON that can be used to call a function from your code. This is a significant advancement as it allows developers to interact with AI in a more structured and systematic way, overcoming the challenges of dealing with unstructured data outputs.\nIn the context of MoodCast, this feature is used to interact with the OpenWeather and Spotify APIs, creating a unique blend of AI, weather data, and music. The project serves as a practical example of how OpenAI’s function calling can be used to solve complex problems and create innovative applications.\nThis blog post will focus on how to use function calling for OpenAI’s chat completion endpoints. It will provide a detailed guide on how to leverage this feature for your applications, with MoodCast serving as a real-world example. Whether you’re a seasoned developer or a beginner in the field of AI, this post aims to provide valuable insights into the potential of OpenAI’s function calling feature.\n\n\n\nLogo\n\n\n\nimport json\nimport os\nfrom dotenv import load_dotenv\nimport openai\nfrom openai import OpenAI\nclient = OpenAI()\nload_dotenv()\n# openai key\nOPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\nopenai.api_key = OPENAI_API_KEY\nfrom IPython.display import display, Markdown\n\nFirst let’s check what openai chat completion say about current weather\n\nresponse = client.chat.completions.create(\n    model=\"gpt-4-1106-preview\",\n    messages=[\n        {\"role\": \"user\", \"content\": \"what's the current weather in Tokyo?\"}\n    ],\n    temperature=0.3,\n    seed=1,\n)\n\n\nprint(response)\n\nChatCompletion(id='chatcmpl-8dISDM1s7co80v8cx8z65WwUKkTLQ', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"I'm sorry, but I cannot provide real-time data such as the current weather. To get the latest weather information for Tokyo or any other location, please check a reliable weather forecasting service or website like the Japan Meteorological Agency, Weather.com, or a weather app on your smartphone. These sources are regularly updated and can provide you with current conditions, forecasts, and any weather alerts that might be in effect.\", role='assistant', function_call=None, tool_calls=None))], created=1704376421, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_3905aa4f79', usage=CompletionUsage(completion_tokens=82, prompt_tokens=15, total_tokens=97))\n\n\n\ndisplay(Markdown(response.choices[0].message.content))\n\nI’m sorry, but I cannot provide real-time data such as the current weather. To get the latest weather information for Tokyo or any other location, please check a reliable weather forecasting service or website like the Japan Meteorological Agency, Weather.com, or a weather app on your smartphone. These sources are regularly updated and can provide you with current conditions, forecasts, and any weather alerts that might be in effect.\n\n\nAs we can see openai does not have any information about the current weather. So we will use openweather api to get the current weather and then use openai chat completion to generate a response.\n\nLive Data using OpenWeatherMap API\nYou can signup here to get your api key https://openweathermap.org/api\nI have stored all the api key infomration in a .env file. You can create your own .env file and store your api key there.\n\n# .env file\n\nOPENWEATHER_API_KEY=your_api_key\nOPENAI_API_KEY = sk-key\nSPOTIFY_CLIENT_ID = 4444633gfdggdggdgdgdg\nSPOTIFY_CLIENT_SECRET = 23rtrrgrdgdr5353terg\n\nimport requests\n\ndef get_current_weather(city, api_key=os.getenv(\"OPENWEATHER_API_KEY\"), unit=\"metric\"):\n    \"\"\"Get the current weather for a given city using OpenWeather API.\"\"\"\n    base_url = \"http://api.openweathermap.org/data/2.5/weather\"\n    params = {\n        \"q\": city,\n        \"appid\": api_key,\n        \"units\": unit\n    }\n    response = requests.get(base_url, params=params)\n    if response.status_code == 200:\n        data = response.json()\n        #print(data)\n        weather = {\n            \"location\": data[\"name\"],\n            \"temperature\": int(data[\"main\"][\"temp\"]),\n            \"rain\": data[\"weather\"][0][\"main\"],\n            \"unit\": \"Celsius\" if unit == \"metric\" else \"Fahrenheit\"\n        }\n        return json.dumps(weather)\n    else:\n        return {\"location\": city, \"temperature\": \"unknown\", \"unit\": unit, \"rain\": \"unknown\"}\n\napi_key = os.getenv(\"OPENWEATHER_API_KEY\")\nweather_info = get_current_weather(\"Nagercoil\")\nprint(weather_info)\n\n{\"location\": \"Nagercoil\", \"temperature\": 26, \"rain\": \"Clouds\", \"unit\": \"Celsius\"}\n\n\n\ntype(weather_info)\n\nstr\n\n\n\n\nSpotify Music\nWe can create an application on spotify and get the client id and client secret. We can use these credentials to get the access token and then use the access token to get the current weather based playlist.\nhttps://developer.spotify.com/\n\n# !pip3 install spotipy\n\n\nimport spotipy\nfrom spotipy.oauth2 import SpotifyClientCredentials\nimport os\nfrom IPython.display import Image, display, Audio\n\ndef search_song(song_name):\n    # Set up your Spotify credentials\n    client_id = os.getenv(\"SPOTIFY_CLIENT_ID\")\n    client_secret = os.getenv(\"SPOTIFY_CLIENT_SECRET\")\n\n    # Authenticate with Spotify\n    client_credentials_manager = SpotifyClientCredentials(client_id=client_id, client_secret=client_secret)\n    sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)\n\n    # Search for the song\n    results = sp.search(q=song_name, limit=1, type='track')\n    tracks = results['tracks']['items']\n\n    # Display the first result\n    if tracks:\n        track = tracks[0]\n        return json.dumps({\n            \"song\": track['name'],\n            \"artist\": ', '.join(artist['name'] for artist in track['artists']),\n            \"album\": track['album']['name'],\n            \"album_cover_url\": track['album']['images'][0]['url'],\n            \"preview_url\": track['preview_url']\n        })\n\n    else:\n        return \"No song found\"\n\nsong_name = \"Appadi podu\"\nsong_details = search_song(song_name)\nprint(song_details)\n\n{\"song\": \"Appadi Podu\", \"artist\": \"Vidyasagar, Krishnakumar Kunnath, Anuradha Sriram\", \"album\": \"Ghilli (Original Motion Picture Soundtrack)\", \"album_cover_url\": \"https://i.scdn.co/image/ab67616d0000b2737bbef42d34fd25b14b2a54ea\", \"preview_url\": \"https://p.scdn.co/mp3-preview/df03b78315eaa0c7e20d66ea17dcf1a5fa4e6e3e?cid=706a549bcf8a4575b6e1dd3fc24f5f95\"}\n\n\n\n# display song details\nsong_details_json = json.loads(song_details)\ndisplay(Image(url=song_details_json[\"album_cover_url\"], width=100), )\ndisplay(Markdown(f\"[{song_details_json['song']} by {song_details_json['artist']}]({song_details_json['preview_url']})\"))\nprint(song_details_json[\"album\"])\n\n\n\n\nAppadi Podu by Vidyasagar, Krishnakumar Kunnath, Anuradha Sriram\n\n\nGhilli (Original Motion Picture Soundtrack)\n\n\n\n\nCreating Tools\n\navailable_tools = [\n        {\n            \"type\": \"function\",\n            \"function\": {\n                \"name\": \"get_current_weather\",\n                \"description\": \"Get the current weather in a given location, use farhenheit\",\n                \"parameters\": {\n                    \"type\": \"object\",\n                    \"properties\": {\n                        \"city\": {\n                            \"type\": \"string\",\n                            \"description\": \"The city to get the weather for\",\n                        },\n                        \"unit\": {\n                            \"type\": \"string\",\n                            \"description\": \"The unit to use for the temperature, metric is default\",\n                            \"enum\": [\"metric\", \"imperial\"],\n                        }\n                    },\n                    \"required\": [\"city\", \"unit\"],\n                },\n            },\n        },\n        {\n            \"type\": \"function\",\n            \"function\": {\n                \"name\": \"search_song\",\n                \"description\": \"Search for a song on Spotify and display its details including the artist, album, album cover, and a preview link if available\",\n                \"parameters\": {\n                    \"type\": \"object\",\n                    \"properties\": {\n                        \"song_name\": {\n                            \"type\": \"string\",\n                            \"description\": \"The name of the song to search for\",\n                        }\n                    },\n                    \"required\": [\"song_name\"],\n                }\n            }\n        }\n    ]\n\nIn the MoodCast project, JSON is utilized to define tools for function descriptions, which are essential for the OpenAI function calling feature. This feature enables the AI to generate structured data outputs, specifically JSON objects containing arguments for functions described in the API call. For instance, the get_current_weather function is defined to fetch current weather data for a specified city, while the search_song function is designed to search for songs on Spotify. These function descriptions are crucial as they guide the AI in generating the correct JSON output that can be used to call functions from the code, thereby facilitating the integration with OpenWeather and Spotify APIs.\nTo effectively use function calling with OpenAI, developers must clearly define their functions, including the name, description, and parameters, in a JSON format. This structured approach allows the AI to understand the context and generate the appropriate JSON output. The OpenAI API documentation provides guidelines on how to describe functions for function calling, emphasizing the importance of a clear and detailed function schema to ensure accurate and useful responses from the AI model.\nFor MoodCast, this means that by defining functions like get_current_weather and search_song with precise parameters and descriptions, the AI can produce JSON outputs that correspond to these functions. These outputs can then be used to make API calls to OpenWeather and Spotify, respectively, to create a music playlist that matches the current weather conditions, showcasing a practical application of OpenAI’s function calling capability in a real-world project.\n\ncity = \"Nagercoil\"\n\n\n\nOpenai Chat Completion Function Calling\n\nmessages = [\n    {\n        \"role\": \"system\",\n        \"content\": \"A Song Suggestions Assistant based on local weather in metric and local language\"\n    },\n    {\n        \"role\": \"user\",\n        \"content\": f\"\"\"I am in {city}, suggest 5 songs based on their current weather and their local language\n        and display their album details such as album cover, artist, and preview link.\n        return a json object with keys as song, artist, album, album_cover_url, and preview_url and reason\n\n        key as song_suggestions and value as a list of json objects with keys as song, artist, album, album_cover_url, preview_url, and reason\n        \"\"\"\n    }\n]\n\ntools = available_tools\nresponse = client.chat.completions.create(\n    model=\"gpt-4-1106-preview\",\n    messages=messages,\n    tools=tools,\n    tool_choice=\"auto\", \n    temperature=0.9\n)\nresponse_message = response.choices[0].message\ntool_calls = response_message.tool_calls\n\nWe can also force the model to use some particular function by using tool_choice = {\"type\": \"function\", \"function\": {\"name\": \"my_function\"}} forces the model to call that function.\n\nresponse\n\nChatCompletion(id='chatcmpl-8dISaihzl1Q2k7S09VBau44EwlMMv', choices=[Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_FmoMsWB1hklh6GvT9QmrTX3k', function=Function(arguments='{\\n  \"city\": \"Nagercoil\",\\n  \"unit\": \"metric\"\\n}', name='get_current_weather'), type='function')]))], created=1704376444, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_3905aa4f79', usage=CompletionUsage(completion_tokens=28, prompt_tokens=249, total_tokens=277))\n\n\nAs when openai gonna use function calling, you can see the finish_reason in the response, which indicates we have to call the function with the given arguments and get the results, and pass it to the model again\n\nresponse_message\n\nChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_FmoMsWB1hklh6GvT9QmrTX3k', function=Function(arguments='{\\n  \"city\": \"Nagercoil\",\\n  \"unit\": \"metric\"\\n}', name='get_current_weather'), type='function')])\n\n\n\nresponse_message.tool_calls\n\n[ChatCompletionMessageToolCall(id='call_FmoMsWB1hklh6GvT9QmrTX3k', function=Function(arguments='{\\n  \"city\": \"Nagercoil\",\\n  \"unit\": \"metric\"\\n}', name='get_current_weather'), type='function')]\n\n\n\nTool Calls\n\nfor tool in tool_calls:\n    print(f\"Tool ID: {tool.id}\")\n    print(f\"Call the function: {tool.function.name}\")\n    print(f\"Parameters: {tool.function.arguments}\")\n\nTool ID: call_FmoMsWB1hklh6GvT9QmrTX3k\nCall the function: get_current_weather\nParameters: {\n  \"city\": \"Nagercoil\",\n  \"unit\": \"metric\"\n}\n\n\n\nfunction_name = tool_calls[0].function.name\nfunction_args = tool_calls[0].function.arguments\n\nfunction_name, function_args\n\n('get_current_weather', '{\\n  \"city\": \"Nagercoil\",\\n  \"unit\": \"metric\"\\n}')\n\n\n\nfunction_args = json.loads(function_args)\nfunction_args\n\n{'city': 'Nagercoil', 'unit': 'metric'}\n\n\n\navailable_functions = {\n        \"get_current_weather\": get_current_weather,\n        \"search_song\": search_song,\n    }\n\n\nfunction_response = available_functions[function_name](**function_args)\nprint(function_response)\n\n{\"location\": \"Nagercoil\", \"temperature\": 26, \"rain\": \"Clouds\", \"unit\": \"Celsius\"}\n\n\n\nmessages\n\n[{'role': 'system',\n  'content': 'A Song Suggestions Assistant based on local weather in metric and local language'},\n {'role': 'user',\n  'content': 'I am in Nagercoil, suggest 5 songs based on their current weather and their local language\\n        and display their album details such as album cover, artist, and preview link.\\n        return a json object with keys as song, artist, album, album_cover_url, and preview_url and reason\\n\\n        key as song_suggestions and value as a list of json objects with keys as song, artist, album, album_cover_url, preview_url, and reason\\n        '}]\n\n\n\nmessages.append(response_message)\nmessages\n\n[{'role': 'system',\n  'content': 'A Song Suggestions Assistant based on local weather in metric and local language'},\n {'role': 'user',\n  'content': 'I am in Nagercoil, suggest 5 songs based on their current weather and their local language\\n        and display their album details such as album cover, artist, and preview link.\\n        return a json object with keys as song, artist, album, album_cover_url, and preview_url and reason\\n\\n        key as song_suggestions and value as a list of json objects with keys as song, artist, album, album_cover_url, preview_url, and reason\\n        '},\n ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_FmoMsWB1hklh6GvT9QmrTX3k', function=Function(arguments='{\\n  \"city\": \"Nagercoil\",\\n  \"unit\": \"metric\"\\n}', name='get_current_weather'), type='function')])]\n\n\n\n\nAppending Tool Call Responses to the Message History\n\nmessages.append(\n                {\n                    \"tool_call_id\": tool_calls[0].id,\n                    \"role\": \"tool\",\n                    \"name\": function_name,\n                    \"content\": function_response,\n                }\n            )\nmessages\n\n[{'role': 'system',\n  'content': 'A Song Suggestions Assistant based on local weather in metric and local language'},\n {'role': 'user',\n  'content': 'I am in Nagercoil, suggest 5 songs based on their current weather and their local language\\n        and display their album details such as album cover, artist, and preview link.\\n        return a json object with keys as song, artist, album, album_cover_url, and preview_url and reason\\n\\n        key as song_suggestions and value as a list of json objects with keys as song, artist, album, album_cover_url, preview_url, and reason\\n        '},\n ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_FmoMsWB1hklh6GvT9QmrTX3k', function=Function(arguments='{\\n  \"city\": \"Nagercoil\",\\n  \"unit\": \"metric\"\\n}', name='get_current_weather'), type='function')]),\n {'tool_call_id': 'call_FmoMsWB1hklh6GvT9QmrTX3k',\n  'role': 'tool',\n  'name': 'get_current_weather',\n  'content': '{\"location\": \"Nagercoil\", \"temperature\": 26, \"rain\": \"Clouds\", \"unit\": \"Celsius\"}'}]\n\n\n\n\nSecond Call to get Song Details\n\nsecond_response = client.chat.completions.create(\n            model=\"gpt-4-1106-preview\",\n            messages=messages,\n            tools=available_tools,\n            tool_choice=\"auto\",\n        )\n\nprint(second_response)\n\nChatCompletion(id='chatcmpl-8dISdx8ctxPgd8bD3BDnYCEOmialh', choices=[Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content='The current weather in Nagercoil is 26 degrees Celsius with clouds. Based on this weather, I will suggest songs that convey a sense of peace, comfort, and perhaps contemplation, which is often associated with cloudy days. The local language in Nagercoil is Tamil, so I will be selecting Tamil songs that match the weather mood.\\n\\nI will now search for suitable Tamil songs and provide their details. Please wait a moment while I process this information.', role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_UEVy6FVIVy3V2kwcD36tDRvv', function=Function(arguments='{\"song_name\": \"Mazhai Kuruvi\"}', name='search_song'), type='function'), ChatCompletionMessageToolCall(id='call_XKVJrqRjh1aafYldWeBWNnG2', function=Function(arguments='{\"song_name\": \"Nenjukulle\"}', name='search_song'), type='function'), ChatCompletionMessageToolCall(id='call_I5Gnz9hvK1JuX8cSPFH14aL8', function=Function(arguments='{\"song_name\": \"Uyire Uyire\"}', name='search_song'), type='function'), ChatCompletionMessageToolCall(id='call_KrUYtZqTDopUCua3dRbrOC9B', function=Function(arguments='{\"song_name\": \"Vaseegara\"}', name='search_song'), type='function'), ChatCompletionMessageToolCall(id='call_w724Il0i6dFCDLG4l4OmPY4e', function=Function(arguments='{\"song_name\": \"Aaromale\"}', name='search_song'), type='function')]))], created=1704376447, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_c6efb4aa39', usage=CompletionUsage(completion_tokens=279, prompt_tokens=307, total_tokens=586))\n\n\n\ndisplay(Markdown(second_response.choices[0].message.content))\n\nThe current weather in Nagercoil is 26 degrees Celsius with clouds. Based on this weather, I will suggest songs that convey a sense of peace, comfort, and perhaps contemplation, which is often associated with cloudy days. The local language in Nagercoil is Tamil, so I will be selecting Tamil songs that match the weather mood.\nI will now search for suitable Tamil songs and provide their details. Please wait a moment while I process this information.\n\n\n\ntool_calls = second_response.choices[0].message.tool_calls\n\n\nfor tool in tool_calls:\n    print(f\"Tool ID: {tool.id}\")\n    print(f\"Call the function: {tool.function.name}\")\n    print(f\"Parameters: {tool.function.arguments}\")\n\nTool ID: call_UEVy6FVIVy3V2kwcD36tDRvv\nCall the function: search_song\nParameters: {\"song_name\": \"Mazhai Kuruvi\"}\nTool ID: call_XKVJrqRjh1aafYldWeBWNnG2\nCall the function: search_song\nParameters: {\"song_name\": \"Nenjukulle\"}\nTool ID: call_I5Gnz9hvK1JuX8cSPFH14aL8\nCall the function: search_song\nParameters: {\"song_name\": \"Uyire Uyire\"}\nTool ID: call_KrUYtZqTDopUCua3dRbrOC9B\nCall the function: search_song\nParameters: {\"song_name\": \"Vaseegara\"}\nTool ID: call_w724Il0i6dFCDLG4l4OmPY4e\nCall the function: search_song\nParameters: {\"song_name\": \"Aaromale\"}\n\n\n\nmessages.append(second_response.choices[0].message)\n\n\n\nCall the function and append the results to the message history\n\nfor tool in tool_calls:\n    function_name = tool.function.name\n    function_args = json.loads(tool.function.arguments)\n    function_response = available_functions[function_name](**function_args)\n\n    messages.append(\n        {\n            \"tool_call_id\": tool.id,\n            \"role\": \"tool\",\n            \"name\": function_name,\n            \"content\": function_response,\n        }\n    )\n    print(function_response)\n\n{\"song\": \"Mazhai Kuruvi\", \"artist\": \"A.R. Rahman\", \"album\": \"Chekka Chivantha Vaanam (Original Motion Picture Soundtrack)\", \"album_cover_url\": \"https://i.scdn.co/image/ab67616d0000b2735234d8419de0ffdccc8c27a7\", \"preview_url\": \"https://p.scdn.co/mp3-preview/771e747c73fc6cd5914a4e447f9daf3bd74e38a5?cid=706a549bcf8a4575b6e1dd3fc24f5f95\"}\n{\"song\": \"Nenjukulle\", \"artist\": \"Ashbel Peter, Theertha\", \"album\": \"Nenjukulle\", \"album_cover_url\": \"https://i.scdn.co/image/ab67616d0000b273d3d692e38621d741606588e7\", \"preview_url\": \"https://p.scdn.co/mp3-preview/d48678e7eef2bebd5a099d2b6b1ff5dd299ff102?cid=706a549bcf8a4575b6e1dd3fc24f5f95\"}\n{\"song\": \"Uyire Uyire\", \"artist\": \"Saagar, Na.Muthukumar\", \"album\": \"Santhosh Subramaniyam (Original Motion Picture Soundtrack)\", \"album_cover_url\": \"https://i.scdn.co/image/ab67616d0000b2738b895bdb8ccefee6ab65114b\", \"preview_url\": \"https://p.scdn.co/mp3-preview/c4e812236497ce1f72610be2af10740ad6ecead6?cid=706a549bcf8a4575b6e1dd3fc24f5f95\"}\n{\"song\": \"Vaseegara\", \"artist\": \"Bombay Jayashri\", \"album\": \"Minnalae (Original Motion Picture Soundtrack)\", \"album_cover_url\": \"https://i.scdn.co/image/ab67616d0000b273102f02fa7e7ded2bc5f65653\", \"preview_url\": \"https://p.scdn.co/mp3-preview/2db5c05f48a7214b56c8eed843103ae3f241e00e?cid=706a549bcf8a4575b6e1dd3fc24f5f95\"}\n{\"song\": \"Aaromale\", \"artist\": \"A.R. Rahman, Alphons Joseph\", \"album\": \"Vinnathaandi Varuvaayaa (Original Motion Picture Soundtrack)\", \"album_cover_url\": \"https://i.scdn.co/image/ab67616d0000b27397838a7eeb5f477cfc6707a5\", \"preview_url\": \"https://p.scdn.co/mp3-preview/ed07e1b3e3fe14b55e29c10c5413dd9e04fbe1e5?cid=706a549bcf8a4575b6e1dd3fc24f5f95\"}\n\n\n\nmessages\n\n[{'role': 'system',\n  'content': 'A Song Suggestions Assistant based on local weather in metric and local language'},\n {'role': 'user',\n  'content': 'I am in Nagercoil, suggest 5 songs based on their current weather and their local language\\n        and display their album details such as album cover, artist, and preview link.\\n        return a json object with keys as song, artist, album, album_cover_url, and preview_url and reason\\n\\n        key as song_suggestions and value as a list of json objects with keys as song, artist, album, album_cover_url, preview_url, and reason\\n        '},\n ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_FmoMsWB1hklh6GvT9QmrTX3k', function=Function(arguments='{\\n  \"city\": \"Nagercoil\",\\n  \"unit\": \"metric\"\\n}', name='get_current_weather'), type='function')]),\n {'tool_call_id': 'call_FmoMsWB1hklh6GvT9QmrTX3k',\n  'role': 'tool',\n  'name': 'get_current_weather',\n  'content': '{\"location\": \"Nagercoil\", \"temperature\": 26, \"rain\": \"Clouds\", \"unit\": \"Celsius\"}'},\n ChatCompletionMessage(content='The current weather in Nagercoil is 26 degrees Celsius with clouds. Based on this weather, I will suggest songs that convey a sense of peace, comfort, and perhaps contemplation, which is often associated with cloudy days. The local language in Nagercoil is Tamil, so I will be selecting Tamil songs that match the weather mood.\\n\\nI will now search for suitable Tamil songs and provide their details. Please wait a moment while I process this information.', role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_UEVy6FVIVy3V2kwcD36tDRvv', function=Function(arguments='{\"song_name\": \"Mazhai Kuruvi\"}', name='search_song'), type='function'), ChatCompletionMessageToolCall(id='call_XKVJrqRjh1aafYldWeBWNnG2', function=Function(arguments='{\"song_name\": \"Nenjukulle\"}', name='search_song'), type='function'), ChatCompletionMessageToolCall(id='call_I5Gnz9hvK1JuX8cSPFH14aL8', function=Function(arguments='{\"song_name\": \"Uyire Uyire\"}', name='search_song'), type='function'), ChatCompletionMessageToolCall(id='call_KrUYtZqTDopUCua3dRbrOC9B', function=Function(arguments='{\"song_name\": \"Vaseegara\"}', name='search_song'), type='function'), ChatCompletionMessageToolCall(id='call_w724Il0i6dFCDLG4l4OmPY4e', function=Function(arguments='{\"song_name\": \"Aaromale\"}', name='search_song'), type='function')]),\n {'tool_call_id': 'call_UEVy6FVIVy3V2kwcD36tDRvv',\n  'role': 'tool',\n  'name': 'search_song',\n  'content': '{\"song\": \"Mazhai Kuruvi\", \"artist\": \"A.R. Rahman\", \"album\": \"Chekka Chivantha Vaanam (Original Motion Picture Soundtrack)\", \"album_cover_url\": \"https://i.scdn.co/image/ab67616d0000b2735234d8419de0ffdccc8c27a7\", \"preview_url\": \"https://p.scdn.co/mp3-preview/771e747c73fc6cd5914a4e447f9daf3bd74e38a5?cid=706a549bcf8a4575b6e1dd3fc24f5f95\"}'},\n {'tool_call_id': 'call_XKVJrqRjh1aafYldWeBWNnG2',\n  'role': 'tool',\n  'name': 'search_song',\n  'content': '{\"song\": \"Nenjukulle\", \"artist\": \"Ashbel Peter, Theertha\", \"album\": \"Nenjukulle\", \"album_cover_url\": \"https://i.scdn.co/image/ab67616d0000b273d3d692e38621d741606588e7\", \"preview_url\": \"https://p.scdn.co/mp3-preview/d48678e7eef2bebd5a099d2b6b1ff5dd299ff102?cid=706a549bcf8a4575b6e1dd3fc24f5f95\"}'},\n {'tool_call_id': 'call_I5Gnz9hvK1JuX8cSPFH14aL8',\n  'role': 'tool',\n  'name': 'search_song',\n  'content': '{\"song\": \"Uyire Uyire\", \"artist\": \"Saagar, Na.Muthukumar\", \"album\": \"Santhosh Subramaniyam (Original Motion Picture Soundtrack)\", \"album_cover_url\": \"https://i.scdn.co/image/ab67616d0000b2738b895bdb8ccefee6ab65114b\", \"preview_url\": \"https://p.scdn.co/mp3-preview/c4e812236497ce1f72610be2af10740ad6ecead6?cid=706a549bcf8a4575b6e1dd3fc24f5f95\"}'},\n {'tool_call_id': 'call_KrUYtZqTDopUCua3dRbrOC9B',\n  'role': 'tool',\n  'name': 'search_song',\n  'content': '{\"song\": \"Vaseegara\", \"artist\": \"Bombay Jayashri\", \"album\": \"Minnalae (Original Motion Picture Soundtrack)\", \"album_cover_url\": \"https://i.scdn.co/image/ab67616d0000b273102f02fa7e7ded2bc5f65653\", \"preview_url\": \"https://p.scdn.co/mp3-preview/2db5c05f48a7214b56c8eed843103ae3f241e00e?cid=706a549bcf8a4575b6e1dd3fc24f5f95\"}'},\n {'tool_call_id': 'call_w724Il0i6dFCDLG4l4OmPY4e',\n  'role': 'tool',\n  'name': 'search_song',\n  'content': '{\"song\": \"Aaromale\", \"artist\": \"A.R. Rahman, Alphons Joseph\", \"album\": \"Vinnathaandi Varuvaayaa (Original Motion Picture Soundtrack)\", \"album_cover_url\": \"https://i.scdn.co/image/ab67616d0000b27397838a7eeb5f477cfc6707a5\", \"preview_url\": \"https://p.scdn.co/mp3-preview/ed07e1b3e3fe14b55e29c10c5413dd9e04fbe1e5?cid=706a549bcf8a4575b6e1dd3fc24f5f95\"}'}]\n\n\n\n\nThird Response to get the final results as JSON Object\n\nthird_response = client.chat.completions.create(\n                model=\"gpt-4-1106-preview\",\n                messages=messages,\n                response_format={\"type\":\"json_object\"}\n            )\n\n\nthird_response.choices[0].message.content\n\n'\\n{\\n    \"song_suggestions\": [\\n        {\\n            \"song\": \"Mazhai Kuruvi\",\\n            \"artist\": \"A.R. Rahman\",\\n            \"album\": \"Chekka Chivantha Vaanam (Original Motion Picture Soundtrack)\",\\n            \"album_cover_url\": \"https://i.scdn.co/image/ab67616d0000b2735234d8419de0ffdccc8c27a7\",\\n            \"preview_url\": \"https://p.scdn.co/mp3-preview/771e747c73fc6cd5914a4e447f9daf3bd74e38a5?cid=706a549bcf8a4575b6e1dd3fc24f5f95\",\\n            \"reason\": \"This song has a soothing melody that resonates well with a cloudy and peaceful atmosphere.\"\\n        },\\n        {\\n            \"song\": \"Nenjukulle\",\\n            \"artist\": \"A.R. Rahman, Shakthisree Gopalan\",\\n            \"album\": \"Kadal (Original Motion Picture Soundtrack)\",\\n            \"album_cover_url\": \"https://i.scdn.co/image/ab67616d0000b273d3d692e38621d741606588e7\",\\n            \"preview_url\": \"https://p.scdn.co/mp3-preview/d48678e7eef2bebd5a099d2b6b1ff5dd299ff102?cid=706a549bcf8a4575b6e1dd3fc24f5f95\",\\n            \"reason\": \"The backdrop of the ocean in the lyrics, combined with the cloudy weather theme, provides a tranquil listening experience.\"\\n        },\\n        {\\n            \"song\": \"Uyire Uyire\",\\n            \"artist\": \"Hariharan, Bombay Jayashri\",\\n            \"album\": \"Bombay (Original Motion Picture Soundtrack)\",\\n            \"album_cover_url\": \"https://i.scdn.co/image/ab67616d0000b2738b895bdb8ccefee6ab65114b\",\\n            \"preview_url\": \"https://p.scdn.co/mp3-preview/c4e812236497ce1f72610be2af10740ad6ecead6?cid=706a549bcf8a4575b6e1dd3fc24f5f95\",\\n            \"reason\": \"Its lyrical depth and the warmth of the composition blend nicely with the introspective mood of a cloudy day.\"\\n        },\\n        {\\n            \"song\": \"Vaseegara\",\\n            \"artist\": \"Bombay Jayashri\",\\n            \"album\": \"Minnalae (Original Motion Picture Soundtrack)\",\\n            \"album_cover_url\": \"https://i.scdn.co/image/ab67616d0000b273102f02fa7e7ded2bc5f65653\",\\n            \"preview_url\": \"https://p.scdn.co/mp3-preview/2db5c05f48a7214b56c8eed843103ae3f241e00e?cid=706a549bcf8a4575b6e1dd3fc24f5f95\",\\n            \"reason\": \"This classic love ballad with its serene mood is perfect for a cloudy day lounging.\"\\n        },\\n        {\\n            \"song\": \"Aaromale\",\\n            \"artist\": \"Alphons Joseph\",\\n            \"album\": \"Vinnaithaandi Varuvaayaa (Original Motion Picture Soundtrack)\",\\n            \"album_cover_url\": \"https://i.scdn.co/image/ab67616d0000b27397838a7eeb5f477cfc6707a5\",\\n            \"preview_url\": \"https://p.scdn.co/mp3-preview/ed07e1b3e3fe14b55e29c10c5413dd9e04fbe1e5?cid=706a549bcf8a4575b6e1dd3fc24f5f95\",\\n            \"reason\": \"A refreshing song that\\'s well-suited for when the clouds are out and you crave an uplifting atmosphere.\"\\n        }\\n    ]\\n}'\n\n\n\n# display song details\nsong_details_json = json.loads(third_response.choices[0].message.content)\n\n\nsong_details_json\n\n{'song_suggestions': [{'song': 'Mazhai Kuruvi',\n   'artist': 'A.R. Rahman',\n   'album': 'Chekka Chivantha Vaanam (Original Motion Picture Soundtrack)',\n   'album_cover_url': 'https://i.scdn.co/image/ab67616d0000b2735234d8419de0ffdccc8c27a7',\n   'preview_url': 'https://p.scdn.co/mp3-preview/771e747c73fc6cd5914a4e447f9daf3bd74e38a5?cid=706a549bcf8a4575b6e1dd3fc24f5f95',\n   'reason': 'This song has a soothing melody that resonates well with a cloudy and peaceful atmosphere.'},\n  {'song': 'Nenjukulle',\n   'artist': 'A.R. Rahman, Shakthisree Gopalan',\n   'album': 'Kadal (Original Motion Picture Soundtrack)',\n   'album_cover_url': 'https://i.scdn.co/image/ab67616d0000b273d3d692e38621d741606588e7',\n   'preview_url': 'https://p.scdn.co/mp3-preview/d48678e7eef2bebd5a099d2b6b1ff5dd299ff102?cid=706a549bcf8a4575b6e1dd3fc24f5f95',\n   'reason': 'The backdrop of the ocean in the lyrics, combined with the cloudy weather theme, provides a tranquil listening experience.'},\n  {'song': 'Uyire Uyire',\n   'artist': 'Hariharan, Bombay Jayashri',\n   'album': 'Bombay (Original Motion Picture Soundtrack)',\n   'album_cover_url': 'https://i.scdn.co/image/ab67616d0000b2738b895bdb8ccefee6ab65114b',\n   'preview_url': 'https://p.scdn.co/mp3-preview/c4e812236497ce1f72610be2af10740ad6ecead6?cid=706a549bcf8a4575b6e1dd3fc24f5f95',\n   'reason': 'Its lyrical depth and the warmth of the composition blend nicely with the introspective mood of a cloudy day.'},\n  {'song': 'Vaseegara',\n   'artist': 'Bombay Jayashri',\n   'album': 'Minnalae (Original Motion Picture Soundtrack)',\n   'album_cover_url': 'https://i.scdn.co/image/ab67616d0000b273102f02fa7e7ded2bc5f65653',\n   'preview_url': 'https://p.scdn.co/mp3-preview/2db5c05f48a7214b56c8eed843103ae3f241e00e?cid=706a549bcf8a4575b6e1dd3fc24f5f95',\n   'reason': 'This classic love ballad with its serene mood is perfect for a cloudy day lounging.'},\n  {'song': 'Aaromale',\n   'artist': 'Alphons Joseph',\n   'album': 'Vinnaithaandi Varuvaayaa (Original Motion Picture Soundtrack)',\n   'album_cover_url': 'https://i.scdn.co/image/ab67616d0000b27397838a7eeb5f477cfc6707a5',\n   'preview_url': 'https://p.scdn.co/mp3-preview/ed07e1b3e3fe14b55e29c10c5413dd9e04fbe1e5?cid=706a549bcf8a4575b6e1dd3fc24f5f95',\n   'reason': \"A refreshing song that's well-suited for when the clouds are out and you crave an uplifting atmosphere.\"}]}\n\n\n\ntype(song_details_json)\n\ndict\n\n\n\n\n\nDisplay Model Outputs\n\n# Displaying each song suggestion with its details\nfor song in song_details_json[\"song_suggestions\"]:\n    display(Markdown(f\"### {song['song']}\"))\n    display(Markdown(f\"**Artist:** {song['artist']}\"))\n    display(Markdown(f\"**Album:** {song['album']}\"))\n    display(Image(url=song['album_cover_url'], width=200))\n    display(Markdown(f\"[Preview the song]({song['preview_url']})\"))\n    display(Markdown(f\"**Reason:** {song['reason']}\"))\n    display(Markdown(\"----\"))\n\nMazhai Kuruvi\n\n\nArtist: A.R. Rahman\n\n\nAlbum: Chekka Chivantha Vaanam (Original Motion Picture Soundtrack)\n\n\n\n\n\nPreview the song\n\n\nReason: This song has a soothing melody that resonates well with a cloudy and peaceful atmosphere.\n\n\n\n\n\nNenjukulle\n\n\nArtist: A.R. Rahman, Shakthisree Gopalan\n\n\nAlbum: Kadal (Original Motion Picture Soundtrack)\n\n\n\n\n\nPreview the song\n\n\nReason: The backdrop of the ocean in the lyrics, combined with the cloudy weather theme, provides a tranquil listening experience.\n\n\n\n\n\nUyire Uyire\n\n\nArtist: Hariharan, Bombay Jayashri\n\n\nAlbum: Bombay (Original Motion Picture Soundtrack)\n\n\n\n\n\nPreview the song\n\n\nReason: Its lyrical depth and the warmth of the composition blend nicely with the introspective mood of a cloudy day.\n\n\n\n\n\nVaseegara\n\n\nArtist: Bombay Jayashri\n\n\nAlbum: Minnalae (Original Motion Picture Soundtrack)\n\n\n\n\n\nPreview the song\n\n\nReason: This classic love ballad with its serene mood is perfect for a cloudy day lounging.\n\n\n\n\n\nAaromale\n\n\nArtist: Alphons Joseph\n\n\nAlbum: Vinnaithaandi Varuvaayaa (Original Motion Picture Soundtrack)\n\n\n\n\n\nPreview the song\n\n\nReason: A refreshing song that’s well-suited for when the clouds are out and you crave an uplifting atmosphere.\n\n\n\n\n\n\n\nPutting it all together\n\ndef generate_weather_music(city):\n    messages = [\n        {\n            \"role\": \"system\",\n            \"content\": \"A Song Suggestions Assistant based on local weather in metric and local language\"\n        },\n        {\n            \"role\": \"user\",\n            \"content\": f\"\"\"I am in {city}, suggest 5 songs based on their current weather and their local language\n            and display their album details such as album cover, artist, and preview link.\n            return a json object with keys as song, artist, album, album_cover_url, and preview_url and reason\n\n            key as song_suggestions and value as a list of json objects with keys as song, artist, album, album_cover_url, preview_url, and reason\n            \"\"\"\n        }\n    ]\n    tools = available_tools\n    response = client.chat.completions.create(\n        model=\"gpt-4-1106-preview\",\n        messages=messages,\n        tools=tools,\n        tool_choice=\"auto\",\n        temperature=0.9\n    )\n    response_message = response.choices[0].message\n    tool_calls = response_message.tool_calls\n\n    if tool_calls:\n        function_name = tool_calls[0].function.name\n        function_args = json.loads(tool_calls[0].function.arguments)\n        function_response = available_functions[function_name](**function_args)\n\n        messages.append(response_message)\n        messages.append(\n            {\n                \"tool_call_id\": tool_calls[0].id,\n                \"role\": \"tool\",\n                \"name\": function_name,\n                \"content\": function_response,\n            }\n        )\n\n        second_response = client.chat.completions.create(\n            model=\"gpt-4-1106-preview\",\n            messages=messages,\n            tools=available_tools,\n            tool_choice=\"auto\",\n        )\n\n        response_message = second_response.choices[0].message\n        tool_calls = response_message.tool_calls\n\n        if tool_calls:\n            messages.append(response_message)\n            for tool in tool_calls:\n                function_name = tool.function.name\n                function_args = json.loads(tool.function.arguments)\n                function_response = available_functions[function_name](**function_args)\n\n                messages.append(\n                    {\n                        \"tool_call_id\": tool.id,\n                        \"role\": \"tool\",\n                        \"name\": function_name,\n                        \"content\": function_response,\n                    }\n                )\n\n            third_response = client.chat.completions.create(\n                model=\"gpt-4-1106-preview\",\n                messages=messages,\n                response_format={\"type\":\"json_object\"}\n            )\n\n            return third_response\n\n\n\n\nimage.png\n\n\n\nresult = generate_weather_music(\"Sydney\")\n\n\nsong_suggestions_json = result.choices[0].message.content\n\n\ntype(song_suggestions_json)\n\nstr\n\n\n\nsong_suggestions_json = json.loads(song_suggestions_json)\n\n\nsong_suggestions_json \n\n{'song_suggestions': [{'song': 'Over the Rainbow',\n   'artist': \"Israel Kamakawiwo'ole\",\n   'album': 'Alone In Iz World',\n   'album_cover_url': 'https://i.scdn.co/image/ab67616d0000b27356c868c8c85e7e4e62bd9ec1',\n   'preview_url': 'https://p.scdn.co/mp3-preview/2b0ebc854ece09122c1918aeff6af258493defe9?cid=706a549bcf8a4575b6e1dd3fc24f5f95',\n   'reason': \"This classic song's soothing ukulele and gentle vocals perfectly match the peacefulness of an overcast day.\"},\n  {'song': 'Sweater Weather',\n   'artist': 'The Neighbourhood',\n   'album': 'I Love You.',\n   'album_cover_url': 'https://i.scdn.co/image/ab67616d0000b2738265a736a1eb838ad5a0b921',\n   'preview_url': 'https://p.scdn.co/mp3-preview/877602f424a9dea277b13301ffc516f9fd1fbe7e?cid=706a549bcf8a4575b6e1dd3fc24f5f95',\n   'reason': \"The title itself and the song's vibe are a nod to the cozy feel of the current Sydney weather.\"},\n  {'song': 'Set Fire to the Rain',\n   'artist': 'Adele',\n   'album': '21',\n   'album_cover_url': 'https://i.scdn.co/image/ab67616d0000b2732118bf9b198b05a95ded6300',\n   'preview_url': 'https://p.scdn.co/mp3-preview/6fc68c105e091645376471727960d2ba3cd0ee01?cid=706a549bcf8a4575b6e1dd3fc24f5f95',\n   'reason': \"Though it's not raining, the cloudy skies can bring about the feeling captured by this powerful yet soulful song.\"},\n  {'song': 'Cloudy Day',\n   'artist': 'Tones And I',\n   'album': 'Cloudy Day',\n   'album_cover_url': 'https://i.scdn.co/image/ab67616d0000b273d2cf6639f08099bdb14e388d',\n   'preview_url': 'https://p.scdn.co/mp3-preview/9c49fc0dfef73b4f91d444309b06450c9e30fee5?cid=706a549bcf8a4575b6e1dd3fc24f5f95',\n   'reason': 'This song has a fitting title and an uplifting tone that can bring positivity to a cloudy day.'},\n  {'song': 'Cloudbusting',\n   'artist': 'Kate Bush',\n   'album': 'Hounds Of Love',\n   'album_cover_url': 'https://i.scdn.co/image/ab67616d0000b273ad08f4b38efbff0c0da0f252',\n   'preview_url': 'https://p.scdn.co/mp3-preview/0156aec767cfcbe6bfc80bb9c8ad931169a3d910?cid=706a549bcf8a4575b6e1dd3fc24f5f95',\n   'reason': 'An evocative track that seamlessly aligns with the overcast weather in Sydney, capturing the theme of moving through introspective moments.'}]}\n\n\n\nfor song in song_suggestions_json[\"song_suggestions\"]:\n    display(Markdown(f\"### {song['song']}\"))\n    display(Markdown(f\"**Artist:** {song['artist']}\"))\n    display(Markdown(f\"**Album:** {song['album']}\"))\n    display(Image(url=song['album_cover_url'], width=200))\n    display(Markdown(f\"[Preview the song]({song['preview_url']})\"))\n    display(Markdown(f\"**Reason:** {song['reason']}\"))\n    display(Markdown(\"----\"))\n\nOver the Rainbow\n\n\nArtist: Israel Kamakawiwo’ole\n\n\nAlbum: Alone In Iz World\n\n\n\n\n\nPreview the song\n\n\nReason: This classic song’s soothing ukulele and gentle vocals perfectly match the peacefulness of an overcast day.\n\n\n\n\n\nSweater Weather\n\n\nArtist: The Neighbourhood\n\n\nAlbum: I Love You.\n\n\n\n\n\nPreview the song\n\n\nReason: The title itself and the song’s vibe are a nod to the cozy feel of the current Sydney weather.\n\n\n\n\n\nSet Fire to the Rain\n\n\nArtist: Adele\n\n\nAlbum: 21\n\n\n\n\n\nPreview the song\n\n\nReason: Though it’s not raining, the cloudy skies can bring about the feeling captured by this powerful yet soulful song.\n\n\n\n\n\nCloudy Day\n\n\nArtist: Tones And I\n\n\nAlbum: Cloudy Day\n\n\n\n\n\nPreview the song\n\n\nReason: This song has a fitting title and an uplifting tone that can bring positivity to a cloudy day.\n\n\n\n\n\nCloudbusting\n\n\nArtist: Kate Bush\n\n\nAlbum: Hounds Of Love\n\n\n\n\n\nPreview the song\n\n\nReason: An evocative track that seamlessly aligns with the overcast weather in Sydney, capturing the theme of moving through introspective moments.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items\n\n Back to top"
  },
  {
    "objectID": "posts/understanding-openai-chatcompletion-model-parameters/llm_temperature.html",
    "href": "posts/understanding-openai-chatcompletion-model-parameters/llm_temperature.html",
    "title": "Understanding OpenAI ChatCompletion Model Parameters",
    "section": "",
    "text": "In this notebook, we will go through different parameters in LLM that control the token generation process\n\ntemperature\ntop_p\nfrequency_penalty\npresence_penalty\n\nIn each parameter, we will explore different range of values and discuss about openai’s default values and recommendations. Then in the final section we will go through some real examples to understand how these parameters affect the token generation process.\n\n\n\nIMG_F4CC52CE7F7F-1.jpeg\n\n\nI have written two helper functions highlight_openai_response and highlight for highlighting the probabilities of the tokens generated by the model. Less probable tokens are highlighted in white and more probable tokens are highlighted in green.\n\nquestion = \"\"\"\n\nWhat is machine learning? Explain it to a five year old.\nAnswer within 100 words, 3 paragraphs\n\"\"\"\n\nmodel = \"gpt-3.5-turbo\"\n\n\n\n\nimport seaborn as sns\nfrom IPython.display import HTML\nimport matplotlib.colors as mcolors\nimport numpy as np\n\n\ndef highlight_openai_response(response):\n    messages = response.choices[0].message.content\n    probabilities = []\n\n    for res in response.choices[0].logprobs.content:\n        probabilities.append(np.exp(res.logprob))\n\n    highlight(messages, probabilities)\n\n\ndef highlight(text, probabilities):\n    # Split the text into words, preserving newlines and spaces\n    words = []\n    for line in text.split(\"\\n\"):\n        words.extend([(word, \" \") for word in line.split(\" \")] + [(\"\\n\", \"\")])\n\n    # Remove the last element if it is a newline, added due to the split\n    if words[-1][0] == \"\\n\":\n        words.pop()\n\n    # Ensure probabilities list matches the number of non-empty words\n    normalized_probs = [min(max(0, p), 1) for p in probabilities]\n\n    # Use a Seaborn color palette and map probabilities to colors\n    palette = sns.light_palette(\"green\", as_cmap=True)\n\n    # Start building the HTML string using the 'pre' tag to preserve whitespace\n    html_string = \"&lt;pre style='font-family: inherit; white-space: pre-wrap; word-break: break-all;'&gt;\"\n\n\n    prob_index = 0  # Index for the current probability\n\n    for word, space in words:\n        if word and word != \"\\n\":  # If the element is not a space or newline\n            rgba_color = palette(normalized_probs[prob_index])\n            hex_color = mcolors.to_hex(rgba_color)\n            # Set the text color to black and the background color to the word's color\n            html_string += f\"&lt;span style='background-color: {hex_color}; color: black;'&gt;{word}&lt;/span&gt;\"\n            if space:\n                # Set the space's background color to the word's color\n                html_string += f\"&lt;span style='background-color: {hex_color}; color: black;'&gt;{space}&lt;/span&gt;\"\n            prob_index += 1\n        elif word == \"\\n\":\n            # Add a newline in HTML, and reset the color for the next line\n            html_string += \"&lt;br&gt;\"\n        else:\n            # This case handles multiple spaces in a row\n            previous_hex_color = mcolors.to_hex(\n                palette(normalized_probs[prob_index - 1])\n            )\n            html_string += (\n                f\"&lt;span style='background-color: {previous_hex_color};'&gt; &lt;/span&gt;\"\n            )\n\n    html_string += \"&lt;/pre&gt;\"  # Close the 'pre' tag\n\n    # Display the HTML string\n    display(HTML(html_string))\n\n\nhighlight(\"Hello I am Arun\", [0.9, 0.8, 0.6, 0.4])\n\nHello I am Arun \n\n\n\nimport os\nfrom dotenv import load_dotenv\nload_dotenv()\nos.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n\n\nfrom openai import OpenAI, __version__\nprint(f\"OpenAI version: {__version__}\")\nclient = OpenAI()\n\nOpenAI version: 1.5.0\n\n\n\nseed = 42\n\n\nTokens\nIn large language models (LLMs), tokens are the smallest units of text that the model processes and generates. They can represent individual characters, words, subwords, or even larger linguistic units, depending on the specific tokenization approach used. Tokens act as a bridge between the raw text data and the numerical representations that LLMs can work with.\nIn the context of OpenAI, tokens are the basic units of text processed by their language models, such as GPT-3. OpenAI employs Byte-Pair Encoding (BPE) for tokenization, which is a method initially designed for text compression. BPE identifies the most frequent pairs of characters or tokens and merges them to form new tokens, thus optimizing the tokenization process for efficiency and effectiveness in representing the text data. This approach allows the model to handle a wide range of vocabulary, including rare words or phrases, by breaking them down into subword units.\n\n\n\nimage.png\n\n\nsource https://platform.openai.com/tokenizer\nIn openai chat completion APIs, four parameter controls the token generation process. They are\n\ntemperature\ntop_p\nfrequency_penalty\npresence_penalty\n\n\n\nTemperature\nIn large language models, temperature is a parameter that controls the randomness of predictions by scaling the logits before applying the softmax function. A low temperature makes the model more confident and conservative, favoring more likely predictions, while a high temperature increases diversity and creativity, allowing for less probable outcomes.\nTemperature adjusts the probability distribution of the next word. A higher temperature increases randomness, while a lower one makes the model more deterministic.\nPurpose: It controls the level of unpredictability in the output.\nThe temperature adjustment equation in LaTeX format is as follows:\n\\[\nP'(w_i) = \\frac{P(w_i)^{\\frac{1}{T}}}{\\sum_{j=1}^{V} P(w_j)^{\\frac{1}{T}}}\n\\]\nHere, \\(P(w_i)\\) is the original probability of the word \\(w_i\\), \\(T\\) is the temperature, \\(P'(w_i)\\) is the adjusted probability of the word, and \\(V\\) is the vocabulary size (the total number of words over which the probabilities are distributed). This equation shows how each original probability \\(P(w_i)\\) is raised to the power of the reciprocal of the temperature, and then normalized by dividing by the sum of all such adjusted probabilities to ensure that the adjusted probabilities sum to 1.\n\n0.15** (1/1.9)\n\n0.368437494723581\n\n\n\n0.15** (1/0.7)\n\n0.06652540281931184\n\n\n\nimport pandas as pd\n\n# Base probabilities for 20 words\nbase_probabilities = [\n    0.19, 0.12, 0.10, 0.09, 0.08, 0.07, 0.06, 0.05, 0.04, 0.03,\n    0.03, 0.03, 0.02, 0.02, 0.02, 0.01, 0.01, 0.01, 0.01, 0.01\n]\n\n# Temperatures\nhigh_temperature = 1.9\nlow_temperature = 0.4\n\n# Adjusted probabilities with high temperature\nadjusted_probabilities_high = [p ** (1 / high_temperature) for p in base_probabilities]\n\n# Adjusted probabilities with low temperature\nadjusted_probabilities_low = [p ** (1 / low_temperature) for p in base_probabilities]\n\n# Normalizing the adjusted probabilities for high temperature\nsum_adjusted_probabilities_high = sum(adjusted_probabilities_high)\nnormalized_probabilities_high = [p / sum_adjusted_probabilities_high for p in adjusted_probabilities_high]\n\n# Normalizing the adjusted probabilities for low temperature\nsum_adjusted_probabilities_low = sum(adjusted_probabilities_low)\nnormalized_probabilities_low = [p / sum_adjusted_probabilities_low for p in adjusted_probabilities_low]\n\nwords = [f\"word{i}\" for i in range(20)]\n\n# Create a DataFrame with the words and their probabilities, adjusted for high and low temperatures\ndf = pd.DataFrame({\n    \"word\": words,\n    \"base_probability\": base_probabilities,\n    \"adjusted_probability_high=1.9\": adjusted_probabilities_high,\n    \"normalized_probabilities_high=1.9\": normalized_probabilities_high,\n    \"adjusted_probability_low=0.4\": adjusted_probabilities_low,\n    \"normalized_probabilities_low=0.4\": normalized_probabilities_low\n})\n\ndf\n\n\n\n\n\n\n\n\nword\nbase_probability\nadjusted_probability_high=1.9\nnormalized_probabilities_high=1.9\nadjusted_probability_low=0.4\nnormalized_probabilities_low=0.4\n\n\n\n\n0\nword0\n0.19\n0.417250\n0.111183\n0.015736\n0.493728\n\n\n1\nword1\n0.12\n0.327611\n0.087298\n0.004988\n0.156515\n\n\n2\nword2\n0.10\n0.297635\n0.079310\n0.003162\n0.099221\n\n\n3\nword3\n0.09\n0.281580\n0.075032\n0.002430\n0.076245\n\n\n4\nword4\n0.08\n0.264654\n0.070522\n0.001810\n0.056797\n\n\n5\nword5\n0.07\n0.246693\n0.065736\n0.001296\n0.040677\n\n\n6\nword6\n0.06\n0.227469\n0.060613\n0.000882\n0.027668\n\n\n7\nword7\n0.05\n0.206656\n0.055067\n0.000559\n0.017540\n\n\n8\nword8\n0.04\n0.183756\n0.048965\n0.000320\n0.010040\n\n\n9\nword9\n0.03\n0.157937\n0.042085\n0.000156\n0.004891\n\n\n10\nword10\n0.03\n0.157937\n0.042085\n0.000156\n0.004891\n\n\n11\nword11\n0.03\n0.157937\n0.042085\n0.000156\n0.004891\n\n\n12\nword12\n0.02\n0.127587\n0.033998\n0.000057\n0.001775\n\n\n13\nword13\n0.02\n0.127587\n0.033998\n0.000057\n0.001775\n\n\n14\nword14\n0.02\n0.127587\n0.033998\n0.000057\n0.001775\n\n\n15\nword15\n0.01\n0.088587\n0.023605\n0.000010\n0.000314\n\n\n16\nword16\n0.01\n0.088587\n0.023605\n0.000010\n0.000314\n\n\n17\nword17\n0.01\n0.088587\n0.023605\n0.000010\n0.000314\n\n\n18\nword18\n0.01\n0.088587\n0.023605\n0.000010\n0.000314\n\n\n19\nword19\n0.01\n0.088587\n0.023605\n0.000010\n0.000314\n\n\n\n\n\n\n\n\ndf[\"base_probability\"].sum()\n\n1.0\n\n\nAs we can see that the base probabilities decrease progressively from word0 to word19, starting at 0.19 and going down to 0.01. However, after the adjustment, the probabilities are closer to each other, indicating that the temperature scaling has made the less likely words more probable and the more probable words less dominant.\nFor example, word0 has its probability decreased from 0.19 to about 0.11, while word19 has its probability slightly increased from 0.01 to about 0.024. This adjustment serves to flatten the probability distribution, making the model less certain and more explorative in its word choices.\nThe adjusted probabilities are also normalized, as their sum should equal 1 to represent a valid probability distribution. This adjustment allows for a less deterministic and more varied text generation, which can be useful for generating more diverse and creative text outputs.\nThe temperature adjustment has effectively reduced the likelihood of the most probable word being selected and increased the likelihood of less probable words, thus adding variability to the text generation process.\n\n# plot the probabilities\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(10, 6))\nplt.plot(words, base_probabilities, label=\"Base Probabilities\")\nplt.plot(words, normalized_probabilities_high, label=\"High Temperature\")\nplt.plot(words, normalized_probabilities_low, label=\"Low Temperature\")\nplt.xticks(rotation=90)\nplt.xlabel(\"Words\")\nplt.ylabel(\"Probability\")\nplt.legend()\nplt.show()\n\n\n\n\n\nTemperature : 0( Deterministic)\n\n\nresponse = client.chat.completions.create(\n  model=model,\n  messages=[\n    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n    {\"role\": \"user\", \"content\": question}\n  ],\n  logprobs=True,\n  temperature=0,\n  seed=seed\n)\n\n\nprint(response.choices[0].message.content)\n\nMachine learning is like having a super smart robot friend that can learn things on its own. Just like how you learn new things by practicing and trying different things, machine learning is when a computer program learns from lots of examples and gets better at doing a task. For example, if you show the robot friend lots of pictures of cats and dogs, it can learn to tell the difference between them. It's like magic, but really it's just the computer using math and patterns to figure things out.\n\n\n\nresponse.choices[0].logprobs.content[:5] # first 5 tokens\n\n[ChatCompletionTokenLogprob(token='Machine', bytes=[77, 97, 99, 104, 105, 110, 101], logprob=-0.001537835, top_logprobs=[]),\n ChatCompletionTokenLogprob(token=' learning', bytes=[32, 108, 101, 97, 114, 110, 105, 110, 103], logprob=-0.00058532227, top_logprobs=[]),\n ChatCompletionTokenLogprob(token=' is', bytes=[32, 105, 115], logprob=-0.00044044392, top_logprobs=[]),\n ChatCompletionTokenLogprob(token=' like', bytes=[32, 108, 105, 107, 101], logprob=-0.31134152, top_logprobs=[]),\n ChatCompletionTokenLogprob(token=' having', bytes=[32, 104, 97, 118, 105, 110, 103], logprob=-1.0659788, top_logprobs=[])]\n\n\n\nprobs = []\n\n\nimport numpy as np\n\nfor res in response.choices[0].logprobs.content:\n    probs.append(np.exp(res.logprob))\n\n\nplt.hist(probs);\nplt.xlabel(\"Probability\")\nplt.ylabel(\"Count\")\nplt.show()\n\n\n\n\n\nresponse.system_fingerprint\n\n\nhighlight_openai_response(response)\n\nMachine learning is like having a super smart robot friend that can learn things on its own. Just like how you learn new things by practicing and trying different things, machine learning is when a computer program learns from lots of examples and gets better at doing a task. For example, if you show the robot friend lots of pictures of cats and dogs, it can learn to tell the difference between them. It's like magic, but really it's just the computer using math and patterns to figure things out. \n\n\n\n\n\nHigh Temperature ( More Randomness)\n\n\nresponse = client.chat.completions.create(\n  model=model,\n  messages=[\n    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n    {\"role\": \"user\", \"content\": question}\n  ],\n  logprobs=True,\n  temperature=1.6,\n  seed=seed\n)\n\n\nhighlight_openai_response(response)\n\nMachine learning is when computer programs can learn and improve by themselves.   Imagine you have a puzzle toy with pictures on it. At first it's all mixed up and you don't know how to make it right. When you start solving it a few times, you start getting better and can finish the puzzle faster. That's how machines work too, they start with learning puzzles and every time they make a mistake, they remember that and try not to make the same mistake again. They keep getting better and better! They can use what they have learned to help us, like find things on the internet or even drive cars. \n\n\n\nprobs = []\nfor res in response.choices[0].logprobs.content:\n    probs.append(np.exp(res.logprob))\n\nplt.hist(probs);\nplt.xlabel(\"Probability\")\nplt.ylabel(\"Count\")\nplt.show()\n\n\n\n\n\n\n\nTemperature : 1 ( Default)\n\n\nresponse = client.chat.completions.create(\n  model=model,\n  messages=[\n    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n    {\"role\": \"user\", \"content\": question}\n  ],\n  logprobs=True,\n  temperature=1,\n  seed=seed\n)\n\n\nhighlight_openai_response(response)\n\nMachine learning is when computers learn things on their own, just like how you learn new things. Imagine you have a special toy that can remember things it sees and hears. When you show it a picture of a cat and tell it \"this is a cat,\" the toy remembers that. Then, when you show it another picture of a cat without telling it anything, the toy can recognize that it's a cat too! This is because the toy learned from the first picture.   Machine learning is like that toy, but with big computers. They can learn from lots of pictures, sounds, and information to understand things all by themselves. The more they learn, the smarter they become. They can even help us do things like finding answers to questions, predicting what might happen next, and making decisions. It's like having a really smart friend who knows so many things! \n\n\n\nprobs = []\nfor res in response.choices[0].logprobs.content:\n    probs.append(np.exp(res.logprob))\n\nplt.hist(probs)\nplt.xlabel(\"Probability\")\nplt.ylabel(\"Count\")\nplt.show()\n\n\n\n\n\n\nOpenAI Recommendations for Temperature\n - default is 1 - range: 0 to 2 \n\n\nTop-P (Nucleus Sampling)\nTop-p sampling, also known as nucleus sampling, is a technique used in large language models to control the diversity and quality of generated text. It involves selecting tokens from the most probable options, where the sum of their probabilities determines the selection.\nThe “top p” parameter acts as a filter, controlling how many different words or phrases the model considers when predicting the next word. The lower the value of p, the more deterministic the responses generated by the model are.\nThis method helps balance between diversity and high-probability words, ensuring the output is both diverse and contextually relevant.\n\ndf_p = df[['word', 'base_probability']].copy()\n\ndf_p['cumulative_probability'] = df_p['base_probability'].cumsum()\n\ndf_p\n\n\n\n\n\n\n\n\nword\nbase_probability\ncumulative_probability\n\n\n\n\n0\nword0\n0.19\n0.19\n\n\n1\nword1\n0.12\n0.31\n\n\n2\nword2\n0.10\n0.41\n\n\n3\nword3\n0.09\n0.50\n\n\n4\nword4\n0.08\n0.58\n\n\n5\nword5\n0.07\n0.65\n\n\n6\nword6\n0.06\n0.71\n\n\n7\nword7\n0.05\n0.76\n\n\n8\nword8\n0.04\n0.80\n\n\n9\nword9\n0.03\n0.83\n\n\n10\nword10\n0.03\n0.86\n\n\n11\nword11\n0.03\n0.89\n\n\n12\nword12\n0.02\n0.91\n\n\n13\nword13\n0.02\n0.93\n\n\n14\nword14\n0.02\n0.95\n\n\n15\nword15\n0.01\n0.96\n\n\n16\nword16\n0.01\n0.97\n\n\n17\nword17\n0.01\n0.98\n\n\n18\nword18\n0.01\n0.99\n\n\n19\nword19\n0.01\n1.00\n\n\n\n\n\n\n\n\ndf_p.style.apply(lambda x: ['background: yellow' if x.cumulative_probability &lt;= 0.8 else '' for i in x], axis=1)\n\n\n\n\n\n\n \nword\nbase_probability\ncumulative_probability\n\n\n\n\n0\nword0\n0.190000\n0.190000\n\n\n1\nword1\n0.120000\n0.310000\n\n\n2\nword2\n0.100000\n0.410000\n\n\n3\nword3\n0.090000\n0.500000\n\n\n4\nword4\n0.080000\n0.580000\n\n\n5\nword5\n0.070000\n0.650000\n\n\n6\nword6\n0.060000\n0.710000\n\n\n7\nword7\n0.050000\n0.760000\n\n\n8\nword8\n0.040000\n0.800000\n\n\n9\nword9\n0.030000\n0.830000\n\n\n10\nword10\n0.030000\n0.860000\n\n\n11\nword11\n0.030000\n0.890000\n\n\n12\nword12\n0.020000\n0.910000\n\n\n13\nword13\n0.020000\n0.930000\n\n\n14\nword14\n0.020000\n0.950000\n\n\n15\nword15\n0.010000\n0.960000\n\n\n16\nword16\n0.010000\n0.970000\n\n\n17\nword17\n0.010000\n0.980000\n\n\n18\nword18\n0.010000\n0.990000\n\n\n19\nword19\n0.010000\n1.000000\n\n\n\n\n\n\ndf_p[\"base_probability\"].sum()\n\n1.0\n\n\n\nHigh Top-P ( Includes more tokens to sample)\n\n\nresponse = client.chat.completions.create(\n  model=model,\n  messages=[\n    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n    {\"role\": \"user\", \"content\": question}\n  ],\n  logprobs=True,\n  top_p=1,\n  seed=seed\n)\n\n\nprint(response.choices[0].message.content)\n\nMachine learning is when computers learn things on their own, just like how you learn new things. Imagine you have a special toy that can remember things it sees and hears. When you show it a picture of a cat and tell it \"this is a cat,\" the toy remembers that. Then, when you show it another picture of a cat without telling it anything, the toy can recognize that it's a cat too! This is because the toy learned from the first picture. \n\nMachine learning is like that toy, but with big computers. They can learn from lots of pictures, sounds, and information to understand things all by themselves. The more they learn, the smarter they become. They can even help us do things like finding answers to questions, predicting what might happen next, and making decisions. It's like having a really smart friend who knows so many things!\n\n\n\nhighlight_openai_response(response)\n\nMachine learning is when computers learn things on their own, just like how you learn new things. Imagine you have a special toy that can remember things it sees and hears. When you show it a picture of a cat and tell it \"this is a cat,\" the toy remembers that. Then, when you show it another picture of a cat without telling it anything, the toy can recognize that it's a cat too! This is because the toy learned from the first picture.   Machine learning is like that toy, but with big computers. They can learn from lots of pictures, sounds, and information to understand things all by themselves. The more they learn, the smarter they become. They can even help us do things like finding answers to questions, predicting what might happen next, and making decisions. It's like having a really smart friend who knows so many things! \n\n\n\nresponse.choices[0].logprobs.content[:5] # first 5 tokens\n\n[ChatCompletionTokenLogprob(token='Machine', bytes=[77, 97, 99, 104, 105, 110, 101], logprob=-0.0015492603, top_logprobs=[]),\n ChatCompletionTokenLogprob(token=' learning', bytes=[32, 108, 101, 97, 114, 110, 105, 110, 103], logprob=-0.0005857991, top_logprobs=[]),\n ChatCompletionTokenLogprob(token=' is', bytes=[32, 105, 115], logprob=-0.00047642877, top_logprobs=[]),\n ChatCompletionTokenLogprob(token=' when', bytes=[32, 119, 104, 101, 110], logprob=-1.7854097, top_logprobs=[]),\n ChatCompletionTokenLogprob(token=' computers', bytes=[32, 99, 111, 109, 112, 117, 116, 101, 114, 115], logprob=-0.25018257, top_logprobs=[])]\n\n\n\nprobs = []\nfor res in response.choices[0].logprobs.content:\n    probs.append(np.exp(res.logprob))\n\nplt.hist(probs);\nplt.xlabel(\"Probability\")\nplt.ylabel(\"Count\")\nplt.show()\n\n\n\n\n\n\n\n\nLow Top-P ( More Deterministic)\n\n\nresponse = client.chat.completions.create(\n  model=model,\n  messages=[\n    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n    {\"role\": \"user\", \"content\": question}\n  ],\n  logprobs=True,\n  top_p=0.2,\n  seed=seed\n)\n\n\nhighlight_openai_response(response)\n\nMachine learning is like having a super smart robot friend that can learn things on its own. Just like how you learn new things by practicing and trying different things, machine learning is when a computer program learns from lots of examples and gets better at doing a task. For example, if you show the robot friend lots of pictures of cats and dogs, it can learn to tell the difference between them. It's like magic, but really it's just the computer using math and patterns to figure things out. \n\n\n\nprobs = []\nfor res in response.choices[0].logprobs.content:\n    probs.append(np.exp(res.logprob))\n\nplt.hist(probs);\nplt.xlabel(\"Probability\")\nplt.ylabel(\"Count\")\nplt.show()\n\n\n\n\n\n\n\nOpenAI Recommendations for Top-P\n\n\n\nimage.png\n\n\n\n\n\nimage-2.png\n\n\n\n\nInteractions between Temperature and Top-P\nLet’s experiment the interactions between temperature and top-p\n\nHigh Temperature and High Top-P\nHigh Temperature and Low Top-P\nLow Temperature and High Top-P\nLow Temperature and Low Top-P\n\n\nHigh Temperature, High Top-P\n\n\nresponse = client.chat.completions.create(\n  model=model,\n  messages=[\n    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n    {\"role\": \"user\", \"content\": question}\n  ],\n  logprobs=True,\n  top_p=1,\n  temperature=1.6,\n  seed=seed\n)\nhighlight_openai_response(response)\n\nMachine learning is when computer programs can learn and improve by themselves.   Imagine you have a puzzle toy with pictures on it. At first it's all mixed up and you don't know how to make it right. When you start solving it a few times, you start getting better and can finish the puzzle faster.   Machine learning works a bit like that. It's like a really smart program that learns from doing things over and over again. It gets more and more powerful, by learning from its own experiences! So just like you, the computer program gets better and better at solving the problems it faces. Isn’t that amazing?! \n\n\n\n\nHigh Temperature, Low Top-P\n\n\nresponse = client.chat.completions.create(\n  model=model,\n  messages=[\n    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n    {\"role\": \"user\", \"content\": question}\n  ],\n  logprobs=True,\n  top_p=0.2,\n  temperature=1.5,\n  seed=seed\n)\nhighlight_openai_response(response)\n\nMachine learning is like having a super smart robot friend that can learn things on its own. Just like how you learn new things by practicing and trying different things, machine learning is when a computer program learns from lots of examples and gets better at doing a task. For example, if you show the robot friend lots of pictures of cats and dogs, it can learn to tell the difference between them. It's like magic, but really it's just the computer using math and patterns to figure things out. \n\n\n\n\nLow Temperature, High Top-P\n\n\nresponse = client.chat.completions.create(\n  model=model,\n  messages=[\n    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n    {\"role\": \"user\", \"content\": question}\n  ],\n  logprobs=True,\n  top_p=1,\n  temperature=0.2,\n  seed=seed\n)\nhighlight_openai_response(response)\n\nMachine learning is like having a super smart robot friend that can learn things on its own. It's like when you play a game and get better each time because you remember what you did before. But instead of a game, the robot friend learns from lots of information and figures out patterns and rules. Then it can use what it learned to make predictions or do tasks without being told exactly what to do. It's like having a really clever friend who can help you with all sorts of things! \n\n\n\n\nLow Temperature, Low Top-P\n\n\nresponse = client.chat.completions.create(\n  model=model,\n  messages=[\n    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n    {\"role\": \"user\", \"content\": question}\n  ],\n  logprobs=True,\n  top_p=0.2,\n  temperature=0.2,\n  seed=seed\n)\nhighlight_openai_response(response)\n\nMachine learning is like having a super smart robot friend that can learn things on its own. Just like how you learn new things by practicing and trying different things, machine learning is when a computer program learns from lots of examples and gets better at doing a task. For example, if you show the robot friend lots of pictures of cats and dogs, it can learn to tell the difference between them. It's like magic, but really it's just a computer using math to learn and make decisions. \n\n\n\n\n\nimage.png\n\n\n\n\n\nFrequency Penalty\nFrequency Penalty is used to reduce the likelihood of a token being selected again if it has already appeared in the generated text.\nIt ranges from -2.0 to 2.0, where positive values discourage repetition by penalizing tokens that occur frequently, and negative values can increase the likelihood of repetition. This helps control the diversity of the generated content and prevent verbatim repetition.\n\n\n\nimage.png\n\n\nIn the above example, we can see recommendations such as National Park appeared twice in the generated text. We can use frequency penalty to reduce the likelihood of a token being selected again if it has already appeared in the generated text.\n\nquestion = \"\"\"\n\nWrite 10 slogans for ChatGPT\n\n\"\"\"\n\n\n\nresponse = client.chat.completions.create(\n  model=model,\n  messages=[\n    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n    {\"role\": \"user\", \"content\": question}\n  ],\n  logprobs=True,\n  temperature=1,\n  seed=seed\n)\nhighlight_openai_response(response)\n\n1. \"Unleash the Power of Chat with ChatGPT!\" 2. \"ChatGPT: Your Trusted Conversational Companion!\" 3. \"Get Instant Answers with ChatGPT - Chat smarter, not harder!\" 4. \"Break the Ice with ChatGPT - The Ultimate Conversation Starter!\" 5. \"ChatGPT: With every chat, we'll wow you!\" 6. \"ChatGPT: Making Conversations Magical!\" 7. \"Experience Smarter Chats with ChatGPT - Your virtual chat guru!\" 8. \"Elevate Your Chats with ChatGPT - Your chatbot companion!\" 9. \"ChatGPT: The Perfect Balance of Wit and Intelligence!\" 10. \"Unlock the Potential of Chat with ChatGPT - Conversations made effortless!\" \n\n\n\nHigh Frequency Penalty\n\n\nresponse = client.chat.completions.create(\n  model=model,\n  messages=[\n    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n    {\"role\": \"user\", \"content\": question}\n  ],\n  logprobs=True,\n  temperature=1,\n  seed=seed,\n  frequency_penalty=2\n)\nhighlight_openai_response(response)\n\n1. \"Unleash the Power of Chat with ChatGPT!\" 2. \"ChatGPT: Your Trusted Conversational Companion.\" 3. \"Get Instant Answers and Engaging Chats with ChatGPT!\" 4. \"Elevate Your Conversations with the Intelligence of ChatGPT.\" 5. \"Chat Smarter, With Confidence - Made Possible by ChatGPT!\" 6. \"Discover a New Level of Conversation Excellence with ChatGPT.\" 7. “Experience Artificial Intelligence that Feels Human – Meet chatbot G.” 8.“Make Every Interaction Count – Talk to Our Powerful AI Assistant!” 9.“Unlock Boundless Knowledge and Vivid Imagination– Say Hi to Our Intelligent AI friend!\"  10.\"Connect, Collaborate, Converse like never before - Powered by the Amazingness Of 'Yethe'\" \n\n\n\n\nLow Frequency Penalty\n\n\nresponse = client.chat.completions.create(\n  model=model,\n  messages=[\n    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n    {\"role\": \"user\", \"content\": question}\n  ],\n  logprobs=True,\n  temperature=1,\n  seed=seed,\n  frequency_penalty=-0.5\n)\nhighlight_openai_response(response)\n\n1. \"Unleash the Power of Chat with ChatGPT!\" 2. \"ChatGPT: Your Trusted Conversational Companion!\" 3. \"Get Instant Answers with ChatGPT!\" 4. \"ChatGPT: Making Conversations Smarter!\" 5. \"Connect, Engage, and Learn with ChatGPT!\" 6. \"Elevate Your Conversations with ChatGPT!\" 7. \"ChatGPT: Your Virtual Conversational Superpower!\" 8. \"Experience the Future of Chat with ChatGPT!\" 9. \"ChatGPT: Making Talk as Intelligent as You!\" 10. \"ChatGPT: Your Chatbot Buddy for Every Occasion!\" \n\n\n\n\n\nimage.png\n\n\n\n\n\nimage.png\n\n\n\n\n\nPresence Penalty\nPresence Penalty is a parameter that influences the generation of new content by penalizing tokens that have already appeared in the text. It ranges from -2.0 to 2.0, where positive values discourage repetition and encourage the model to introduce new topics, while negative values do the opposite. This penalty is applied as a one-time, additive contribution to tokens that have been used at least once, helping to ensure more diverse and creative outputs\n\n\nresponse = client.chat.completions.create(\n  model=model,\n  messages=[\n    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n    {\"role\": \"user\", \"content\": question}\n  ],\n  logprobs=True,\n  temperature=1,\n  seed=seed\n)\nhighlight_openai_response(response)\n\n1. \"Unleash the Power of Chat with ChatGPT!\" 2. \"ChatGPT: Your Trusted Conversational Companion!\" 3. \"Get Instant Answers with ChatGPT - Chat smarter, not harder!\" 4. \"Break the Ice with ChatGPT - The Ultimate Conversation Starter!\" 5. \"ChatGPT: With every chat, knowledge expands!\" 6. \"Join the Chat Revolution - Welcome to ChatGPT!\" 7. \"Experience Chat Brilliance with ChatGPT - Seamless Conversations, Unmatched Results!\" 8. \"Chat Smarter, Talk Faster with ChatGPT!\" 9. \"ChatGPT: The Intelligent Chatbot for All Your Conversational Needs!\" 10. \"Unlock the Potential of Chat with ChatGPT - Conversations Redefined!\" \n\n\n\nHigh Presence Penalty\n\n\nresponse = client.chat.completions.create(\n  model=model,\n  messages=[\n    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n    {\"role\": \"user\", \"content\": question}\n  ],\n  logprobs=True,\n  temperature=1,\n  seed=seed,\n  presence_penalty=1.5\n)\nhighlight_openai_response(response)\n\n1. \"Unleash the Power of Chat with ChatGPT!\" 2. \"ChatGPT: Your Trusted Conversational Companion.\" 3. \"Get Instant Answers and Engaging Chats with ChatGPT!\" 4. \"Elevate Your Conversations with ChatGPT's Intelligent AI.\" 5. \"ChatGPT: With You Every Step of the Conversation.\" 6. \"Unlock New Possibilities in Dialogue with ChatGPT.\" 7. \"Experience Natural Language Communication with ChatGPT.\" 8. \"Supercharge Your Conversations with ChatGPT's AI Assistant.\" 9. \"Chat Smarter, Not Harder, with ChatGPT.\" 10. \"Say Hello to Seamless Chats and Intelligent Responses with ChatGPT!\" \n\n\n\n\nLow Presence Penalty\n\n\nresponse = client.chat.completions.create(\n  model=model,\n  messages=[\n    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n    {\"role\": \"user\", \"content\": question}\n  ],\n  logprobs=True,\n  temperature=1,\n  seed=seed,\n  presence_penalty=-2\n)\nhighlight_openai_response(response)\n\n1. \"Unleash the Power of Chat with ChatGPT!\" 2. \"ChatGPT: Your Trusted Conversational Companion!\" 3. \"ChatGPT: Chatting just got Smarter!\" 4. \"Connect with ChatGPT: Your Virtual Chatting Guru!\" 5. \"ChatGPT: Arm Your Conversations With Intelligence!\" 6. \"ChatGPT: Chatting Perfected with Artificial Intelligence!\" 7. \"ChatGPT: Your Personal Chatting Assistant with the Power of AI!\" 8. \"ChatGPT: Elevate Your Conversations to the Next Level!\" 9. \"ChatGPT: Your Smart Friend for Engaging Chats!\" 10. \"ChatGPT: Intelligent Conversations Made Effortless!\" \n\n\n\n\n\nimage.png\n\n\n\n\n\nimage.png\n\n\n\n\n\nInteraction between Frequency Penalty and Presence Penalty\n\nHigh Frequency Penalty and High Presence Penalty\n\n\nresponse = client.chat.completions.create(\n  model=model,\n  messages=[\n    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n    {\"role\": \"user\", \"content\": question}\n  ],\n  logprobs=True,\n  temperature=1,\n  seed=seed,\n  presence_penalty=1.8,\n  frequency_penalty=1.8\n)\nhighlight_openai_response(response)\n\n1. \"Unleash the Power of Chat with ChatGPT!\" 2. \"ChatGPT: Your Trusted Conversational Companion.\" 3. \"Get Instant Answers and Engaging Chats with ChatGPT!\" 4. \"Elevate Your Conversations with AI-Powered ChatGPT.\" 5. \"Let's Talk! With Dynamic Dialogue Made Easy by ChatGPT.\" 6. \"Discover Smarter, More Natural Chats Using ChatGPT.\" 7. \"Unlock a World of Seamless Communication with ChatGPT.\"  8 .\"Experience Human-Like Interactions using our Advanced Assistant -Chat Gpt\" 9 .\"Your Virtual Conversation Buddy – Get Talking With Chat Gpt Now ! \" 10 .\"Revolutionize Your Conversations w \n\n\n\n\nLow Frequency Penalty and Low Presence Penalty\n\n\nresponse = client.chat.completions.create(\n  model=model,\n  messages=[\n    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n    {\"role\": \"user\", \"content\": question}\n  ],\n  logprobs=True,\n  temperature=1,\n  seed=seed,\n  presence_penalty=-0.5,\n  frequency_penalty=-0.5\n)\nhighlight_openai_response(response)\n\n1. \"Unleash the Power of Chat with ChatGPT!\" 2. \"ChatGPT: Your Trusted Conversational Companion!\" 3. \"ChatGPT: Chatting just got Smarter!\" 4. \"Connect with ChatGPT: Chatting with Intelligence!\" 5. \"ChatGPT: Revolutionizing Chatting, One Conversation at a Time!\" 6. \"ChatGPT: Your Virtual Chatting Expert!\" 7. \"ChatGPT: Chatting with Artificial Intelligence that Feels Human!\" 8. \"ChatGPT: Chatting made Easy, Chatting made Powerful!\" 9. \"ChatGPT: Chatting with the Next Level of Chatbot Technology!\" 10. \"ChatGPT: Chatting. Redefined. \" \n\n\n\n\n\nPractical Use Cases\n\nIndustry 1: Creative Writing (e.g., Novels, Short Stories)\n\nTemperature: Set to 0.8-0.9. Higher temperature encourages more creative and unexpected turns of phrase, enhancing the storytelling with originality.\nTop P (Nucleus Sampling): Set around 0.9. Allows for a good range of probable words while still fostering creativity, which is vital in creative writing.\nFrequency Penalty: Set to a moderate value (e.g., 0.5). Helps avoid excessive repetition of words/phrases, maintaining a fresh and engaging narrative.\nPresence Penalty: Set to a lower value (e.g., 0.3-0.4). Encourages some repetition of key themes or phrases, which can be a powerful tool in storytelling.\n\n\n\nIndustry 2: Customer Support (e.g., Chatbots for Service Queries)\n\nTemperature: Set lower, around 0.3-0.4. Ensures more predictable and relevant responses, crucial for accurate customer support.\nTop P (Nucleus Sampling): Set around 0.8. Balances the need for coherent, relevant responses while allowing for some variability to better match customer queries.\nFrequency Penalty: Moderate to high (e.g., 0.6-0.8). In customer support, avoiding repetitive phrases can enhance clarity and professionalism in responses.\nPresence Penalty: Moderate (e.g., 0.5). Helps ensure a variety of information is provided, which can be crucial in addressing diverse customer queries comprehensively.\n\n\nExplanation:\n\nCreative Writing: The settings are designed to maximize creativity and originality, ensuring a rich and engaging narrative.\nCustomer Support: The focus here is on accuracy, relevance, and clarity in responses, which are essential in a customer support context.\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items\n\n Back to top"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Learning Large Language Models - Explained Intuitively",
    "section": "",
    "text": "Master the Art of Function Calling in OpenAI Assistants API: A Comprehensive Guide for Beginners\n\n\n\n\n\n\n\nllm\n\n\nopenai\n\n\nfunction calling\n\n\nopenai assistants api\n\n\n\n\n\n\n\n\n\n\n\nJan 5, 2024\n\n\nArun Prakash\n\n\n\n\n\n\n  \n\n\n\n\nMoodCast: Leveraging OpenAI Parallel Function Calling for Real-Time Weather-Based Music Playlists\n\n\n\n\n\n\n\nllm\n\n\nopenai\n\n\nfunction-calling\n\n\n\n\n\n\n\n\n\n\n\nJan 3, 2024\n\n\nArun Prakash\n\n\n\n\n\n\n  \n\n\n\n\nUnderstanding OpenAI ChatCompletion Model Parameters\n\n\n\n\n\n\n\nllm\n\n\nopenai\n\n\n\n\n\n\n\n\n\n\n\nDec 17, 2023\n\n\nArun Prakash\n\n\n\n\n\n\nNo matching items\n\n Back to top"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "I write and teach about my learnings in large language models.\n\n\n\n\n\n\nNo matching items\n\n Back to top"
  }
]